{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bt  diff filter size.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_C4HNL0yLes"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import random\n",
        "import torch \n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from random import choice\n",
        "from random import uniform\n",
        "from numpy.random import randint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-V7SxJqywTz"
      },
      "source": [
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((140,140)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "               \n",
        "    \n",
        "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cLCkkMFbdnV",
        "outputId": "c10daee0-2135-4229-9a02-fdca9b2ab407"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miQRANRZy-Ra"
      },
      "source": [
        "num_classes=4\n",
        "num_batches=16\n",
        "num_epochs=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS65XuhtZwob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f1a645-440f-4b3e-9bb0-5c572c3f0cc4"
      },
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuGKtGUGy-61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dffbf926-63e8-4fc0-eb14-27881baaa899"
      },
      "source": [
        "train_path='/content/drive/MyDrive/brain_mri_images (1)/Training'\n",
        "test_path='/content/drive/MyDrive/brain_mri_images (1)/Testing'\n",
        "train_loader=DataLoader(torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=num_batches, shuffle=True)\n",
        "test_loader=DataLoader(torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
        "    batch_size=num_batches, shuffle=True)\n",
        "classes= ('glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor')\n",
        "print(f'Number of training examples: {len(train_loader)}')\n",
        "#print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_loader)}')\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "#print(labels.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 22\n",
            "Number of testing examples: 4\n",
            "torch.Size([16, 3, 140, 140])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC5K2L00thNC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6a7a78a9-26c2-464e-b557-1091d3a45627"
      },
      "source": [
        "def imshow(img):\n",
        "    img=img/2 +.5               #% x= (x-mean)/std\n",
        "    npimage=img.numpy()\n",
        "    plt.imshow(np.transpose(npimage, (1,2,0)))\n",
        "    plt.show()\n",
        "dataiter= iter(train_loader)\n",
        "images, lables= dataiter.next()\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print (' '.join('%5s' %classes[lables[j]]\n",
        "for j in range(16)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAB3CAYAAAD4twBKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9R5Bc55Uu+N303tuqQjmgYAgQAEmBTZCi6KmmfPfixbzZTExMRG/mbXo1bzfbiV7OZiJ68WJmoiNG7SRR3ZJa3f1EsUkAJERYAlUw5X1mpff+zqL4HfyZyKzKAskWWlEnoqKqMm/m/e9vjvmO03RdxyEd0iEd0iH9YZHh9z2AQzqkQzqkQ/rq6ZC5H9IhHdIh/QHSIXM/pEM6pEP6A6RD5n5Ih3RIh/QHSIfM/ZAO6ZAO6Q+QDpn7IR3SIR3SHyB9Lcxd07Q/1jTtvqZp85qm/dev4x6HdEiHdEiHNJi0rzrOXdM0I4AHAN4BsA7gdwD+s67rs1/pjQ7pkA7pkA5pIH0dmvuLAOZ1XV/Udb0B4McAfvg13OeQDumQDumQBtDXwdxHAawp/69/8dohHdIhHdIh/TuR6fd1Y03T/gzAnwGA0Wh8odPpgBCRpmkYBBdpmgaDwQCHwwGfzweDwYBarYZ6vY52uy3X8fMmkwlWqxVWqxW6rqNcLqNcLqPRaAy8R78xWCwWGI1GVKvVL/3sXyfZ7Xa0Wi00m82hP6NpWt8fYHceO50OOp2O/P9VkNvtRrlclu/db3zqONXXeq8zGo0wmXa3davVkr91XUe73e66n67r8j3NZvOxZ9M0DW63G4VC4Qme8N+PDAYDnE4nSqVS1+tGoxFGo/GxuTIYDDIf3OfqNTyLBoNB5rzVasFsNsNgMMg8Go1G+S7OHfdLv/1nNpv/w50hPuNepO47TdPkvKjzAjzab5qmwWQywWQyyVy12+19zxbf59x6vV7k8/mUruvhftd/Hcx9A8AR5f+xL17rIl3X/xLAXwKAz+fTS6VS1wZTNxwnyWg0wu/34+2338Y777yDpaUl/PznP0c6nRZGX6/XoWka7HY76vW6TITf78e7776L06dPY3V1FX//93+Pubk5tFqtro3Zu9n5fywWg8/nw+3bt7ueQ2U4/97Uu3kA4MSJE0in09jc3OyaP5I6Vk3TYDabYbfb4Xa7EQwG4ff74XQ6YbFYAAC1Wg3pdBpbW1tIpVKo1+uPMcgnoQsXLuB3v/sdKpXKnvNHYe50OuHxeNBut9FoNGA2m+FyueBwOB57HqvVikajgVarBbfbjU6nA5PJhFQqhVKphE6nA6vVCqPRCKvViocPH/YVXkajERcvXsS//Mu/PDZ3XyWpSs2TkM1mw4svvohLly51vR4OhxEIBGAwGGA0GoWBeL1eFItFpFIpYf7cB5VKRRQlh8MBm80GTdOQSqVgt9thsVhQKpVgNBphNpvh9/ths9nQbDbR6XTQbrdRLBaxsrLStU80TUM8HofH48GtW7eefLL+HejEiRPY2dnBxsYG3G433G43gMfXSdd1WK1WxONxjIyMoFgsYnl5GWazGRaLBSaTSebXYDCg0WjAZDKJgKzVapiYmIDH40EikcDKygrK5bIIVpUf8afVaiGRSKDT6eDVV1/FP/7jP64Meo6vg7n/DsCMpmlT2GXq/wOA/3G/D6kTRoapPpzBYEAwGMS7776Lb3/72/jd736Hv/u7v4PT6YTX6xUNrdFooFAowOFwwOVyiTZfrVbx13/917h48SK++93v4gc/+AHy+Tw2NjbQarW6xtBvLMOMXaVe4fR10H4WzqDxqYfZ6/VidHQUIyMj8Hg8MBqNAIB6vY5yuQyTyYSxsTHEYjHMz89jfX0dtVpNnqvdbndZTE/yDKReocofu92OkZERtFotlMtlGWu5XBYmXygUZCzUuFwuF0qlEkwmE8xms/wYDAbE43Houo7Z2Vl5nkH0ZZnvQebgoJ9TNb7e76Emyffsdrs8q81mQzAYhMfjQSaTgcFgEMbjcrnQbDZhNpvhcDigaRrC4TCy2SxarRZsNhtMJhNcLhfsdnuXNk9ttHcth3mWYc9Zr7LS7wzsdTZI/ZSjQfdVeRHJ6XRienoa4XAYa2tr2NraQiQSwfHjxwFANPJMJoNCoQCz2Yzp6WnYbDZ0Oh2kUiksLi7C7/fj6NGjsNvtWFlZQSaTGTiO3vOyF33lzF3X9Zamaf8FwK8BGAH8N13X7w752a7f/NtgMCAQCOC73/0u3n33Xfz2t7/F+++/D4fDAafTCaPRiE6nA4PBIJqExWLpMitpon700UdoNpv40Y9+hG9/+9v427/9W+Tz+b7wwLDMeZBm/PuquNnL2NVxGAwGeDweBAIBHDlyBKOjo/D5fDCbzWi1WigUCtjZ2UGlUkGxWBRNb3x8HM899xw0TUMikUCr1YLBYEC1Wn0MEht2jL3jVA8RNRez2YxQKCSMmkLb4XAII8/n89B1HRaLReACu90OXdeRz+fhdDrR6XTESvB4PHC73Xjw4AGy2ayMoXcdh1nLYZjI10W9zEkdi6ZpsNlsMJvNACCMOpvNyvySGQcCATQaDVQqFRgMBlitVmH2uq6LVm61WtFutxGPx5HL5eB2u2WdCH02Go0u2GUvJUOlg1jA/ZSVQdftJZiHXbd+59vn82FiYgKhUAjLy8tIJpMYHR3F2NgYrFYrgF14p91uw+VyIZfLoVKpwGg0CgoRjUbh8XgwOzuL27dv4/Tp05iZmRFB0QtT90Km+9HXgrnruv5LAL884GcAPHoQ9WHsdjtefvllfPvb38bHH3+M999/XxgSANEWqEGoTN1sNkPTNDHl/X4/Pv74Y7RaLfzgBz/A5uYm/vVf/xX1er3vQdlvA/RO9LDX98O1vyrqpzVRSIbDYUxPT+PUqVPw+/3ClLPZLLa2tpDL5UTjIATTbDbh9Xpx8uRJGAwG3L17VyCvfD6PYrGIarXaVzjvNxf9DqpqrXk8HoRCoa7Xk8kkqtUqPB4POp0O6vU67HY7zGYzisUiXC6XaKgGgwFms1nwfUIxBoMBmUymL9Y5SKhzTOr/vZ/rdyB7Me2DzFG/7yX17hl1v6oKDS0X/h8MBlEsFmE2m5FOp+HxeGCxWJBOp+FyuaBpGqrVKqLRKFqtFmq1GhqNhjCtYrEIt9sNp9OJVquFer3e5eegJdz7nF9GCKprYjQaEQqFMD09DbPZjGw2i2KxKEpJP2bcbw0Oot3zs7z3xMQEgsEgFhYWUCgUcPr0aYRCIWHehFAAiI+QlhT9F+Rtp06dwtLSEmZnZ/Hcc8+Jf29zc7MLNlbHMwz93hyqe5HKmKxWK2KxGN577z1sbGzgpz/9qWjndHZomgaHw4FqtSoaB7Eui8UiWia/MxqN4tKlS6hWq/jOd76DhYUFPHjwQBhdP21jP61jmGey2+0IBoOIx+MIhULi5K3X69jZ2UE6ncbOzo7gbvvRoGv6MQLO0fHjx3HhwgXYbDZks1nBmyuVCprNJjRt1yHUaDS6YI7V1VWEQiEEg0EcP34ctVoNmUxGzPZms4lGozHUPA0SAuohMhgMsNvtgqk3m00Ui0VxVnE9CbVYLBa0223Y7XYEAgFUKhWkUil5vdPpiDJA2KZerz82vr3mvfeg917fO+/99s5eTH8QvNBvjvopBOrB13UdtVpNIEuTyYR0Og2z2Qy32412u41KpYJ0Oo1qtQqv1yuCzuFwCLS5s7Mj8+pyuUQ7p7Vcq9VQqVTkPrQWhoFO9nrO3tcMBgMikQjGx8fh9/tht9sxNjYGYHcPRCIRlEolPHjwANeuXcP6+joajUbXnD0J0crhfUZGRhCPxxEMBrGxsYF8Po/jx4/D4/EAgDipycA7nQ6q1WrXvJE4LqfTiePHj2Nubg7Xrl3D2bNnMTMzA6vViuXl5Sd+jqeGufdqyiqccubMGYTDYfzFX/yFMEn1oJGZm0ymLgbNA0CG32630Wq1YLVaEQqFcOPGDcRiMbz77rtYW1sTptrPcfKkzwTsRoYcPXoUJ0+ehNPplPG0Wi04nU6BGOi8XFxcxP3795FOp5/o3oM0l2AwiLNnz8LpdGJ+fl4EWrvdlsPK6CJqYA6HA61WC+12G6VSSRjjyMgIdF0Xja1SqaDVau1rgfR7nt75pskaCoXQbDaRSCRgsViEYWmahnq9jkajgVgsBpfLBa/Xi1wuh1arhUqlImvdarXg9XphNptFYHU6HdhsNoEU9hpbv3HuZeoPskRMJhMsFosIz35REr37rZ+SMSyTNJlMYs1QwaFTlFaX0WjEkSNHsLy8LDg6LVin04lsNivWiqbt4vvlchnhcBherxfVahWNRgOlUgm6riMSicBiscDv9yOZTD4mCPeLOun3HITRzp49iyNHjiCdTmN+fh7JZBKdTgetVgsulwsjIyM4deoUxsbGMDk5ic3NTVy+fFkcu8MIzr3GomkaxsbGMDExAbfbjZWVFaysrGBqakoUEHV/kInTclSVT13f9VVR8eA5mp6ext27d3Hjxg0899xzmJqaQqvVwsrKyhP5tZ4a5t5LfGCDwYDTp0/j3r17WF9fF8bO9wwGA2w2m8AxAMTs5gR3Oh1YLBY0Gg2Z7GAwCJPJhA8++AB//ud/jrGxMczPz8sk9jL5vTBXlUmoGpnJZMLU1BTOnTsHYNdkTSaT8Hq98Hq9MBqNyOVyACCalNFoxMmTJ3H06FF89tlnePjwIVqt1mNjIJMYNHf9GEMoFBLH2NzcHEqlEmZmZlAoFFAqlVAqleDxeATSsNvtCIfDMBgMKJfLcDgcsFqtqFarqFar4tcYHR1FoVBAvV5/DN5S76/+vRdWrEbHVKtVlEolEcpkTsFgUHwuTqcTlUoFPp8PDodDoCKr1YqxsTE4nU4kEgnUajUR8g6HA263G/l8fqg53I/6MXWbzYZAIIBYLIaxsTGBl8gkk8kkNjc3sb29LVE8/b5rEMw2aBy6rmN0dBSTk5PCRAhXETaIRCLiTN3e3pawUZ6pUCiEQqGAZrMJu90Oj8cDTdNQq9WwsbEBn88Hr9eLWq2GWq2GVqslFgDPlgrPHISR8tnsdjvOnz+PI0eOoFgs4pNPPsHGxoaErdJvkMlkkMlksLy8DIfDgUAggHPnzuGtt97C1atX8fnnn++pVOxFPNs+nw+xWAx+vx937tzB6uoq/H4/fD5fl3LJ71S1bVo3BoMBrVarK1yXzwAALpcLp06dwp07d3D79m184xvfQDweRz6fF0XvIMreU8fcexmB3W7H6Ogofvazn8HhcCAYDAJAV/wutU+aQyRq7qr2xOt1XYfL5UIqlcL9+/dx9uxZLC4udsV0qzRI6+BhUKECAHA4HHjppZcQj8dRq9VgNBqRyWRQKpWEoROnDgQCwjidTqcIoTfffBN+vx+fffaZQEu9Wt1eEl293mg0Ih6PQ9M0FItFub/T6cS5c+dw48YNbG5uotlswmAwiJZptVrhdrtRqVTg8XhQr9flee12OwqFAjweDyYnJ1Eul5HJZB7DCQfRIHii3W6jWq3CbDbDZrOhXq9L6J3JZEKhUECtVoPL5ZL3q9UqbDYbRkdHUSwWxQQOhUJIJpOoVCrw+/0AgEKhgE6ngyNHjiCRSMhBHIZ6cXd1Lfi33W7H+Pg4Lly4gNOnTyMajcJisSCXy6Fer3c5OguFAmZnZ3HlyhWsrq6iXC533YvfOQyEo44vGo1KZJDNZhOMPRAIoN1ui3MUgIQ4UolQ92G1WhULIxAIwOfzIRAIoF6vI5/PiyU0MjKCQqEAo9EIr9cLp9PZJTgPwpgMBgO8Xi/ee+89mM1mzM7OYnl5uUtxoB+Be5xM02AwoFKpYH19HT6fDy+++CK2traQTCaHune/+QQgz72+vo6trS2Ew2FMTk4KtMoxcI3UiCFd3w0M4J4mTNN7HwqR48eP4+7du3jw4AFOnjyJSCSCbDZ7YL/cU8Pc+2l7mqbB5/MBAObn5xGJRLqcpQC6EiuoLdXrdTHjSXS6Ejrg++FwGPPz83jttdfwq1/96rGwyGFMdQoQ/rbb7XjrrbcQi8XQaDRQq9WwtraGTqcDn88n2ikFQrPZRKlUQj6fF6YUjUbRbDZx4cIFtFot3Lhxo2tsw8Ifqibk9XrRaDSwsLAAo9EIn8+HF154AeVyGblcrit6YmRkRDZhKBRCq9WS+Gaj0Yhms4lKpSJa/Pj4uGhw+XxeGPxeGucgc7nT6Qgj9Pv9krBGc5dzHo/Hsb29LRExZEilUgkWiwUejwf5fB7NZhNOpxMmkwmlUgntdhupVArPPPMMVlZWsLm5uae1sRf14sKhUAhvvvkmXn31VQlt++ijj5DP51Eul0U4MmdjenoaL7/8Ms6ePYtLly7h8uXL2Nraekxo99PmB1Gn00EikcDIyAgAiN+EeQI+nw/VahU+n0+iOQhj8XqGPfLelUoFFosFDodD1mBpaUnwdfrGcrncY1bRfph777OZTCa88cYbKJfL4rh1Op1ybiikms0mHA6HxOy3220JmkgkEjCZTIhGo7h48SL+6Z/+6bHExYOucbvdxsrKCtxuN2ZmZroYN7Vyau88S/wcfT5UDGq1WpffkOtNHjE6Oort7W2MjY2JRUqlbFh6apg78LgprOs6pqamsLW1JZEONGvVKAD1PTJ/4BETpBlMDzVhm3a7DafTiWQyiZGREUQiESwtLXWNaRgmrzJqs9mMd955B6Ojo2g0GlhcXEStVpNoBavVinK5DJvNJpowF5gwUqvVwtbWliRGvPrqq3A4HLh06ZI8Ty9e3EuqxUKML5/PSwLE5OSkRJfcv38fhUIBXq8XsVgMDocDXq8XZ86cwfz8vGgVHKfZbEa9Xsfq6qokYAQCAbz00kvodDpYWVlBKpXqylLsZfT9YAxg92DHYjGBAarVKgKBAMxmM+bm5uD1ehEOh5FOp0VzZEw2o0CoHbfbbWxsbCAQCODYsWNwu924ffu2OINnZmZw9uxZZLNZVCqVfffnXvvAaDRienoa7733Hk6fPi2aV7PZRK1WQ6fTgdfrFejKYrGgXC4jGAzi2rVrsFqtePPNNzE5OYmf/vSnYkUOCyf0+gMY4bK9vY1OpyOQwvr6umi5hLr8fr8IZGrpFPZcd5vNBmDX0nA6nbKnVew4HA6jUCggnU7LmvY6efci7oHJyUlMTk7is88+E7+L2+0WhujxeBCNRlEoFOByuWQuuQ8IewYCAezs7ODMmTPY3NzEtWvXhhpHv3FpmibQHp2duq6LhataDrSyycidTmfXOhEa5BnuheN0fTdpksmDo6OjklR4EHpq6rnTnFQ3g91ux8WLF3Hr1i14PB4xy+12OwCI1ru9vS3aBDPk+F0mkwlbW1vY3NwEsMs8ms0mWq0WLBYLrFarOOdOnjz5mDd7P3NSFSpGoxGvvPIKpqen0Ww2MTc3h3w+LxvOarWK9VCv1wVHazQasjmNRqPEa29vb6NSqSCbzeL73/8+jhw5Is+tbp5B88mNw7/n5ubEbM1mswgGg7h+/TqazSZcLpfANg6HAxaLBcvLy3K4fT4fCoUC7t+/j4WFBXz++edYX19HqVSCy+XC5uYmAoEAXnvtNRw9ehShUKhL0HJMg+aVf1ssFoyOjiIQCMjr+XweN2/eRD6fx/b2NtbX1wVeMplM8Hg8aDab2NrakpC9Wq2GdrsNm82GWq2GXC6HxcVF6LoumZgLCws4ceIERkdHh4I81LGrZDAYMDU1hT/5kz/B6Ogorly5glu3biGfz8NgMMDn82FsbAwWi0WYjsvlgtvtRjgcxvj4OJxOJy5dugSv14sf/vCHMqaDRnnwM9Sw7Xa75H0AQDQaxc7ODprNJrLZLLLZLPL5PCqVijiZ7XY7Tp8+3QWBqg7qra0t8V8wDLLdbmN+fh7ZbFYcjAexNkgmkwlnz54VC3F9fV2scpfLJQLJarVKBm0wGEQoFBIBwPyMVCqFZDKJZDKJN954A9Fo9LE5HWZ+zWYzPB4PSqWS+H00TXss+or/E55RLQ01gY5zymt6IUl+t8/nEx7xJKHST53mDjxyqo2Pj+PEiRP4m7/5GzF3OBmUkoxvpfkGPMLUDQaDOCMYqsXX1b81TcP29jamp6dFo+nFtocZ88zMDC5cuIBarYb5+XmYTCaJ1KD2o5pnTJ6yWq3iUOOm5kGjVVEul/HCCy8IvKNaK8NqIplMBp1OB6FQCEePHsXq6qocUprsbrcb8Xgcn3/+OTY2NmCxWDAxMYFOp4Pr169jYWFBUvspKL71rW8hlUohk8lgcnISZ8+eRblcRj6ffyyhpXesKi4J7EbdzM3NIRaLYWpqCrVaDffu3UOpVILdbkc+n0cmk8HU1BRGR0eF4TARhxoUQ/5oZdBJrGpNm5ubGB0dFXiGpSuGheRIoVAIP/zhD+F2u3Hnzh0kEgm4XC6x5mw2m6w9X2NmJ6GHZDKJtbU1VCoVXLhwAW+88QZ+/vOfi39GpX4HnUKH43e73aLcbGxsYGNjQ0IVCcMxhh2ACIBAIIAXX3wR5XIZ9+7dk1A+4sFknsViUaznZDKJnZ0d1Ot1STAjo1PXdhCDUuc7Go1iZmYG6+vrskZMsCND7w2YsFgsUiKA4byEi2w2G1KpFKLRKP74j/8YP/7xjyXiapj15Xe5XC6k02lMTEzA6/XKZ9vttoSaqmugKgGq0qoGYPB/wjmEZsjbgsGgxPBzPg9CTw1z78dEY7EYisUi8vk8RkdH5VD2Ro+YzWaUSiUJM6QHW9d3Q7omJyclgYCaqNFolLhsYpTj4+Nd8fD7bUpex6y+t956C0ajEffv35cD4fF4ZPEZ6QMA5XJZIlN4+KvVqoyT96/X68hkMlhfX8exY8fgcrlQLBYPxNQpzKLRKFwuFwKBgCQtMfGCoZBOpxOrq6siNK1WKy5duoRsNiuaPFPQT506hZWVFczNzQnOOTo6imPHjmFxcRFLS0tdzL0fY1fhGr7PVO3Tp08LTsqCU2TAOzs7GBsbQzAYFIeq0+mU2HW32w2j0SgJVqqjUg3/nJubw6lTp+DxeJBKpfqOb7+5PXv2LM6dO4cPPvgAd+/eRSgUEjzVarV2RWpRA7bZbLBarVhaWkI6nZawQ0JdL774IlZXV/HRRx8NVVQK6A4fJFzB3Inp6Wk5P6FQCO12G8lkElarFeFwGNFoFPF4XHwEq6uryOVyMBqNOHHiBCKRiOQdEL4hpmy32xGJRLC8vCz7ktY1xzMMJGMwGPDcc8/BZrMhn8937Qs1AYtWMDVmo9EoQQmdTkeS26gEOp1O3Lt3DydPnsSFCxfw8ccf7zuXvWtMC9tqtcrzqAXWaJHzdQpxXdcloIJogTofPJscK/dcq9USC2FnZwder1fCS4ce94Ge8mumXkzW6XSiWCxKBAedk5w4buJwOAyLxSKmOCeb8bxer1eSDDhxlUoFjUZDJH25XBbh0OsEHGbMZJwsOFStVkWzZro/i5tRE+D7DOlToRs6JwFIfLmmaYhEIsIQ9xI6qhZnMpkwMjKCCxcuYGJiAvl8HnNzc7Db7V2V6er1OrLZLKLRKABgbGwMfr8fc3NzWF1d7frOWCyGb33rWzhz5gxarRZ2dnawvb2NcrkMu90Ov9/fJaj6zVnva6pQY+SNw+GQcEY6l5hQMz4+jrNnz2J8fFycp+l0GqVSCcViUaAY4sOE9fi72WwimUyiXq8jFovtu9b9xmwwGHDq1Ck8fPhQtH8KFDWigxAG/QEAJJQ0m81KZJDBYMDGxgYajQa+9a1vwel0DnWgyVTIJFgYbXJyEtPT03C5XFKGgf4nMmC3242JiQmcOHECa2trmJ2dlXyHTqeDYDCIY8eOYXt7W6KLeIYASBJcNBrFhQsXMDIyIt/dD3obRH6/H2fPnkUikRCG7ff7xQpzOp2w2+1dGrtaeoTwSbFYxPr6OnZ2dvDw4UOplrm+vo4XX3xRLPxhYS+bzSZJfjyTzFvgPBNOAR5V42SRO2C3VhMhYIvFIpYd54XnVNXQCeNVq1WB2Q6SK/DUaO7A404hFoRSTTA1BJLXBQIBMc+ZTENtmZOvOi1U5x1xeppqnLxeB+Ag4vcdP35cYBRqjWazGU6nE1NTU8KwP/vsM4E6WMHQZDJJJT1gN6pFHYOmachms5KsMT8/fyDowG6345vf/CY8Hg/+6q/+Cpubm3C5XIJVc16PHj0qmkUgEBCNye/3iybHTRyJRORzgUAAm5ubmJ+fx7lz5xCNRiXdut989Y6732uNRgPJZBI2mw2nT5/GyMgIfD4fcrkcNjY2EA6HBVdtNpsoFAooFAoIBoPw+XxSrMnr9QrezD1AAW4wGFAoFLC+vo6RkRHMzs4ODceRjEYjwuEwEokEcrkc7HY7nE6naO4qXqpWCqSG5na7xemqaRq8Xi8ymQzu37+PZ555RqAolQatOQUj4UCu4dLSkmTrcsyNRkMUjEwmg9/85jeYmZmB3++XHAG32w1N241A+93vfifWMQCBPQiZ0L9ACDQYDApTHNaRevToUTidTty8eVPClKnB12o1CWXlWhKeYZAB75NOp9FoNMTvs76+DpfLhWq1ikgkgmg0ioWFhaHXmBF4vCerO1JJUC081QpWIULCmK1WC7lcDqFQSBRNTdstj0Khz3wDABgdHcXq6qrws96s6r3oqWLu3Jw8eNzYaghjo9EQia1iW/Rc01kYiURgNptF4+X1xKppljPagiZzL1RA6rdBeY3ZbMaJEydQq9WwubmJQqEgYWOapglskEwmJcyNyS0MO7t16xZyuZzEGHOhWQmx1WpJnRWae6qm24/4us1mw9TUFK5fvy5p0Q6HQxg7Ez8ajYakm6sahNfrxdTUFHZ2dpBMJmWDJhIJ6LoumXeFQgFLS0s4efJkF3PfS3tTD4Xq62i320in0zhy5IiY1p999hm2trbEGcix2mw2+Hy+rp+dnR05lAzjUyE3Mni73Y5sNovjx4+L9cd5HZRDoO4PMutqtSraGPddsVjswp+pgDQaDXg8HjnchPAY9cGwU1W7HoY4LovFIlDfzZs3UavVhBGSKfMskGHRcgiFQlICw+v1YmRkBLFYDDabDUtLS8hms6JB89mpUTKHg/i+U6oAACAASURBVEEBDoejKwppLyavaRpGRkaQyWSg67pYXxR+xPh5LcOZuUZkftlsVkphkPFzfQjbhMNhca4PQ9wvvZaoynuoCDHQwe/3I5VKiYXIOefzaJomETc8h7S8AAg/MplMUoK7n7K0Fz01zL0fM7VaraKZsaIfF5b1LsikaS45nU7BXykVVa1fxcUodcvlsiR1DKoO2U/Kq1oZte9Wq4VQKCRjM5vNSKVSEs7XbDbRbDalSFOn08Hdu3cl9IyLrjIPlidoNBqCww0T587Ny7C48fFxLC4uijVD83pqagqpVEqYtOq0BiCx0NTim80mQqGQhPcRNiqXy7hz5w7eeeedLqY2DPWL66ZwNxh2C4i98MILgjuGQiHB43VdF7N1fX1drvH7/TKnqVTqMZOW+Cwdg4y24HuDSN0PZMBmsxkzMzNYXFyUKB4KPgpsKhLU6ovFImq1msTeUzmhM7TZbHYluwyLXdtsNmneQcuXMIIqcLkvCB3t7Owgn8+LtkyLgZYt/R1sXsJoGgDC0Kjh+v3+rn08zLhpqeu6juXlZbjdbvkOJssFAgFxQgKP4sWpJdMpu7W1JevkcDhEwWL46bBaO8fOfA+eHZ6N3uciDq8iDpqmyT5gkTu/34+NjQ0RBhw7FTe1ACLhuoM6VZ8a5q6awzywjUZDNjpjaolBcgKYbceDbjAYxBylNKU5YzQ+KhbFSBv1O5jw0nuI9tqYlMg2mw3JZFIqDXo8Hml0QJyVi8SUaVYrZFwwAHFa8Xl48FW8WLUyBpHKgCqVCpaWlvDss89KaBwxaNZZYQ1vzqHKCHlvAF1p5fV6HceOHYPX68XS0pJAIcwe5WeGsS7UcQO7GYEs28DOWTabDTMzMwCAfD4vFhKjdlgplCa8y+WSdVdrm/OeJpMJExMTwmCDwaA4Vfdbc3VuLBYLgsEg7t27h1gsJnHzLKPLcahUKpVQr9dRKBTgdrslcsXlckm9HO6rYZi6SmwwMTc3h2KxKAlAfGaWvUgkEnA4HGLFsSooGSKFzcLCAiKRCJxOJ9xut2jBapw2c0jI2Bjq2Qu19iOOjQJezY9gwhyzaOnLyOVyYuUQhmGIKRUL8gzev1gsIpPJIBKJDKUg8XO1Wg26rsua0CnOc0EFQrWmeX5VBZLCtVKpSD0e4JEioVawpR+B7xFlOMg+eGqYu8rUudiFQkGiZMjg6vW6MHgWgyKsAnSnh/O32iWGqdNcdDL40dHRvuUH9pPwvVBSPB7vMhW5yMlkUqJAWI8DgKTrc6MQi6dWDeyWCdC03SxBanL9oKNB4+t0OtjZ2ZHCWaFQCAAkFXppaUlMV0b1qJoDiXAYny+dTsNk2m3moes6EokENjY2sLi4KDHF/eax91D1blibzYbp6WkAu8JuenpaYIxMJoPV1VVxhDLr1Ol0Ip1Oy3cXCgWJOGBaPMfAa5jAxnLAkUgEDx48kLkd5iARX6X2zhDeeDwukE+hUMCdO3eEMVSrVRQKBRw9ehTf+MY3EAqFUK/X8fDhQ1kvhkoeFJYBIMoBNXBaCnzuTqcjHarUchO8nrXKG40GlpeXxafh9/tFeQIg9YU0TROLhPeu1WqSiKZakXuNm8XparVaV3FAh8MhyhJzRDqdjvhUWDeHQqzdbkvtJhWiMRqN0uyFOPh+xGdTYReuO7V3KjFUJNRoGWZa0/Hucrlw48YNERiEjXjWyOcI3xENaDQa+1Zd7aWnhrn3Hihd17G1tSWHXDVngV1nKyUc4RcyHZq4AERzpmnFjUEIgp16gsEgfvnLX3bhXsNSu92WBWRMO6NlaIGofTh5gAkh8ZmZmQlA4qO5Aehz6G0LOMy86rouZmmlUpHDQycPDzk3sJonwLEQH1ZTqjVNEwjE6/UKI1pbW8P4+PiBME3176mpKWmmEQ6HhZEzWoGClIxF1Z5oWRDLrtfr4mOgwGLEFUsI08xnSVtq2cNACdQQmSdAXDUSicDtdsNisWBmZgb5fB4LCwuCeT///PM4c+aMZHZWKhVUKhVJxLLb7WJVqRrcMHuTGDqfjREa/DuXywnEoe5PzsEf/dEfIRKJSMMWapn0C/Cs7ezswGKxiHOQsBPXSU0I3GvcqmLGCB3CgCaTqUtjZtix3W4Xh6vBYOhi7IxKYp167hdmZBMmI4Pdi3h2OHc8O73nhb4OnlOecTqDNU3DlStXRElRwyjVeeLepbLHBjV8/T8kc+egVUm/vr4ujhKa3QDEsapiwuohV0MlVRiGvR7pYMtkMsjlctLcgaUHhtWKeW2r1UI2mxVzuFKpyCFWtRZqEQDEeUdpTMyRz8cxE8tm2FW5XO5bubLffKpCgG3zSAaDQZIxcrmcbFR+joKEh00VvupmJMS0ubkpmcGVSkUyblVrbBjtTbUEqPkS/+dvNSsY2I2WYoJOp9NBNpsVBkdGo2bq8rP8TfOZlfv2M9dVyEt1fHFd1tfXAQCnT59GKpVCp9NBIBCQei8PHz6E2WxGoVBAsVhEIBDAvXv3UCgUBGrg2tAp37umexH9P/xpNpsIBoNSxjefz8NoNAq0Qr8B4QyfzydOUTVrVZ0vdV6BXYFSLBaRzWZFsRpWuKvJexQQXD/Cbtz3hNfa7TYmJycF6iB8YrFYHiutzL+JWTOaKJ1OD2WZ87OVSgWZTEb8Z8CjVnrce/yMwWAQNIAwV6lUwquvvorFxUVxHHM/MpnQZDKhWq3K/9Ti+0X77UdPVZy76szTdb0rGoLmCQ+4as6ommcymRSmSA2UUhWA1J9gEkSr1cLY2BgSiYTEw/abwL0wY13Xsb29DQDSQLhYLKJcLneZXIzD1zRNEpj4HIzlVZkLx86NZLVasbOz0/X+XqTOZTabFeczn40WDasrqmFdPMCq8OHm4+ZVHUHMHjQajRgbG0OtVnustswgUoUQGQkPOp2B1OJ6Y9UtFovAIbVaTRxXTBKiAOAhVxmlSswKHubgqHOkZk6zVlCz2UQqlZK6IEajEfl8HtPT03A6nZiZmcFnn30GYDfUbWVlBYlEQpQNNXaaERXqffcjJhl1Oh2JWqKVWi6XZS/SciPzIbOfm5vDysoKFhYWAEA0YPV8sqQGcxxYPZJRNxSswzJ4ziXDgGl18Xl6LTOn04loNCq15T0ej0CWquBXG9AAkDj/g+Q1cH0JFTEKhveIxWKoVqtot3dLSfv9ftRqNQQCAczMzAjM6fV6sbq6KhFzXCOj0SgNVKjUmM1mEQCEd9XnGoaeGuZOjQB4dPBqtRp2dnbg9/u7NolqNnOzkdm43e6uyBP+5uamcCgWiyK5x8fHcevWLdHuOIbekMNBxAxXmo8qI1S934RiwuEwYrGYODepRdGh0mw2pdoiNwyjBogJ8/kHUe+YGYdNHJT4JrNd6Yyk1s7v54ajFqTOkRqaRuZrtVoxOTkppQcO4gDieG02m1gTnENV21YjC1RhpY6F5Wo5D72WDH+rTHoYrb2XeNiobdOvoWm7ER4bGxu4e/euWEIGw27LNWZ0rq+vS7IWIcNIJCI+FzUjcj/mznmg5UhYiJ2+2J6Q5SaAbqHHudvY2MCnn36K27dvy5lRney8jrVdqF3SV0QrWU3s2Y90XZfwT84r9x0jelRrSWXW6vmikKECSMiNmcLcQ1NTU10W6H5j4/ebTCaUy2UpF6JpmviewuGwNLoxGo345JNPMDc3J4qlzWbD6uqq9CfQtN2ucMeOHROIjAyfeDsVU4aUDivggacIluk36E5nt8Kgz+eTypBM4WVSEDcAQxnVSWBjCZpVKpzDhWo0GojH41Jxkcy8V9Pbb0JZvIyYbSAQEIcON6bFYsHJkyelHKrb7UYoFEI2m5VGDoRqAEhMf71el8JdOzs7Q5vn6pxWq1Wsra0hEolgZ2dHTP5Wq4WZmRnEYjE8fPgQ6XS6K1lJNW2BR0JPtYpoOXU6u+VKo9GoOI0OSq1WqyssUmU6ZDC8P9CN16rX86fXh0Kh0CvAAoEAqtXqUA0m+ll1W1tbAB5lIno8Hty7dw8GgwGff/45DAYDXnrpJWSzWUxPT+P27dtIJpMoFouYmZnByZMnJTRO13Up5dBrTQzDLNU9Tk19ZGRE8HBGs6gOQhWu8vl8AsexFR8jTFTYjvPGAAcyI563YaM7KKxzuZzEdAOPkgyBR8W4eD6Iq/NsURNWNWpadqpfjs/ELOd+tXt615Z5B9FoFNlsFh6PR5IVuZ8Yeq36cdQWn9TMGZRAwVIqlbC8vNylCLLkiOpzq1QqjwV77EdPjebeS3yotbU1xGIxOdD0HHPjcBMRE2PkBCvfURsFHmXVEeoBIN1+UqlUF9auarB7Ea8hQ2QkipqcojomiWeWy2WYTCYcO3ZMokGI23IDqEWQYrFYl3UxDCSj/u50OlhYWJD0fUbK+Hw+jI+Pi7Bk3Dc/y4OjalK8Pw84D0+9Xkc4HJZiUoOaYKhj72W8/C5CLSoDImOhZURNV7XeVMuJOLEqpDlm1RrhM/AgH4T4HcTWDQaDxGt//PHHuHHjBsLhMDqdDjY3NxEMBnHlyhXRRh88eCDRSpx3Fovq9/z7EZks/Uu9sJ/P55NKmapVqmmaROwsLy9LiG6pVEIikZBImn4Qmnpm1Phvwpz7EdeDobRcW0IRxNB5HxYKK5fLKBQK4oSmFUFlg9e6XC4JfSb/uH37tlSv3IsoEBgZZLfbpRsY23IyMonOXeBRBA3nixF6vcojmTZ9VKqCynr1AGS9DmIJ78vcNU37b5qmJTVNu6O8FtA07V80TXv4xW//F69rmqb9n5qmzWuadlvTtOeHHYg6cHWzbGxsSKQDDzMZCR0PqpbCFOV2u421tTU59HTykWkyTjYej0uNa96z5/n3hWWAXVN4dXUVnc5uAkcul0MymZREEHr5qTkRtmGdGWbbqUyIDDcUCmFjYwOrq6vDTudjcwpACpAFg0ExoQuFAi5fvoyFhQW0221kMhnZcNyI1Kx4uClkVUbJjXr27FmUSiUkk8mBGZ795lJlGhTQqsbVqzWSGbJ+O/0JxN7pjFM1fn4/Q2s5fvV7DgrLqIlvuVxOauJTeajVapicnMT3v/99uN1uNBoNnD59Gu+99x6mp6el2Tshjnq93gVPDBPR0UuMsWdEUa/fgck4vTBboVAQhYSRaFwrtT4/YSxmfKqRI2r2eG9zif3OUCaTEaHGKpUsKcKzAECc5w6HQxQ87tNea5sCX7UI6BeLx+P7Zn1ybxMBYFVNu90uHb4YSkuLUFXoOO/1el34lurToh8un88jmUxie3sbuVxOBBpDS1X/1bA0jOb+fwP4457X/iuA/67r+gyA//7F/wDwHoCZL37+DMD/dZDBqAeYC8SJs1qtEq/MRSeT4XV0PhH/pCas4u+M6+X/R48excLCwmOMUB3LXhKT77Xbbdy6dUuiPdjdR60To+KzTL6gVkwTTNWmmDXpcrlw7dq1rvII/M695rJ3nK1WC7du3RLzltmcW1tb0HUd6XRaYsVVQcPP8nWGY/KQU1C43W6cOXNG4J1+4+sdV79xbm9vIxqNSjgg506FVDTtUSYmrST2TmULOFWw9q4p90Wns1sYa2pqSmr+D0N8NjJSh8OBTCYDt9sNv9+PaDSKs2fP4tixY1IYDoBkKLJI2/HjxzEyMiKOaO5z1nVhEttec6Y+GwApy8uyDKqloqa+qzkTnU5HIIpeOIsCN5PJdD0/NVZaaK3WbkN1u90uPQr6ja933BTA7OxlMBik8ByDIyis1O9iWQr2elB9MsxGJ/zKBEVd16Wz05TS3Ho/YtIZzyWVyPX1daTTabk3+QvnlMql6jvSvvADqCHarKXDXsUAuhLYnoS574u567r+b5qmTfa8/EMAr3/x9/8D4LcA/rcvXv9/9d2d/4mmaT5N0+K6rm8NO6B+GOn29jZisZgwoV4cmDAN26w5nU7R0smY+AM8anbB8EKGrgF7a5V7ka7rmJ+flyqFo6Ojom2opiUTmPid3HCU7mwIwOiNyclJfPrpp3LwhmXs/d7X9d2omcuXLwv+S0jr7t27orUxEoVMRQ3FUnMJVMFUqVTw0ksvoV6v49q1a49pbarmr46z33wvLy/j5ZdflqQ1rjcPDTc7DzEPQ+/e4X25B3qtIgoOZg8z4mm/8alUqVQEwyYDGBkZkSJviUQC9Xodd+7cwebmJhwOB2ZnZyUiiMk35XJZon3UmjI0/YchjrXVakk551wuh0wmI7ACzwoL1qnMBoCEQjIem1Uu1VIIxLfVTErVIvJ4PNLz9CDESqBWqxWJREJgH+CRUAQeJY6pihDhGNUq07RdZyd7Dfj9fhw5cgTxeBzlclngnL2ICgWzmCkUDYbdeutLS0uSI0BHNaOOVIuXAqzdbksNJ5aoZlkEtWOXpmmSaKb6wA5CT+pQjSoMextA9Iu/RwGsKdetf/HaY8xd07Q/w652L7idqrF/cY0wzeeeew6ZTAbNZlPMKzWUSzXD2+22OC2ZXKSW6jSbzVJcbHNzU2qOq2Pox4z2o2q1ikuXLsHv9+OVV17BZ599JtYGv5+JROFwWOAmVrKkWUzv/tGjR7G+vo579+513WdYvL0f6bqOzc1NXLp0CRcuXJCoDMbhqoJT1c7J4HuZPCNERkdHcf78eXzyySe4f//+gbFrlUqlEu7cuYNwONwVPsofFWcnHKBqmWQ0vXOhWj1kAOzRykiSYdZb/U4WtXK5XJIkk8/nBbY4duyYREUxD4Khb1arVWomNRoNpFIpgQvIwNS9yd/99qW6ZzudDu7du4f33nsPW1tbCAQCyGQy8Pl80mjZ7XZLDD0hwomJCTlLZNyBQECaaqtrQByfGDYju2w2G/x+Py5duvTYGgwK41MZoBqazHh8lseg4sG14/0ZHUWFjaGgwCMrZnp6Gp3Obt/ddDqNlZUVPHz4cCB0SFKd79vb25iamhKHtQqtsBImBUq5XJZ7qmtDQcGicqwzQ4uYWexqRn4qleo6j8PSl3aofqGlHwwU3P3cX+q6/g1d17/R28y65zokk0lZZDIjMh0SnYS9Jjy1YjW5oV6vI5lM4tixY3j48GHXvQ4qHfk50urqKq5evYpqtYpXXnlFxryxsYFarSZhahQ4vCcdVgx7pDZ3+fLlgYxy0FgHWR/86XR2W/h9+OGHaLVa0kg5Ho9LVARrktN8ZPoz/2+1WggGg5Im/8Ybb2BxcREff/xxVzYu52aQSd47f/z/2rVrMBgMOHLkiOQj8EcNf+OhUKEHMiJew8/zepXBs074/fv3H4vSGWZuO50OSqUSGo0GwuGwpOgXi0Vp3p3L5VCr1ZDNZrGysoJCoSA+pEKhgEQigXK5DJfLhUgkgrGxMTHx2TJOPdh7zSVpZ2cHy8vLiEQiEp6XSqWkAFihUBCGyM/21jYh86RfgnNGBk+4YWtrCzs7OwgGgxKNxeSzYYjXqU7wN954QxrL8MzSAqPVwH2pvqZab4yo4R61WCw4d+4c5ufnRWnYj1mqPhjCUjy/FFZjY2M4efKkdF2jM5tWuxqZpWm7AQrcJ2o0zcTEhCRqUsDu7OxI2eSD8qYnZe4JTdPiAPDF7+QXr28AOKJcN/bFa/sSN4s62ZyURqOBra0tCW1kphoZvq7rgtcxQYllAGhyUiMxmUxSpdHlckkIG8cw6O+9hI/KpDqdDm7evImlpSUUi0U8++yzACCOVEbDMGyqUqlImVQy2jNnzsDr9eLy5csCb/ST2oPGNMwm0PXdAk+XLl3C3NwcJicnpUzykSNHMDY2BgBSroCMz2KxIBKJSFkIXdfx9ttvI5FI4Je//CXW1ta6Mmh779nPOutHtVoNly9fhsvlwsTEhBwWCjoyeDpdechVJ696TzICtYyBWhdlaWnpwFo7v5uOvnA4jJmZGXHYA7v1d+hY52ebzabU4GHROBaXm56eFoWAe0Md1zB+FjLBGzduSEJXNBoVYcdoJBXTVROF+Fw8U6rw5P9s7kIrZGJiQkoA3L179zGNeBBzUoV0sVjE5cuX8cEHH8Dn8yEYDMo6cX2r1WqXklEqlZDP56XNH5UQMvpmsym9SNm0/urVq13Q3F6k4vzNZlPa/lHAMdqM2fEMs/R4PJLxzrng/DIqjbktuq6LfygUCkmQCP0yw0Cx/ehJYZmfA/ifAPwfX/x+X3n9v2ia9mMAfwQgPyzezoH3S2bSdR0PHz7E6dOnsbW1BaPRKIlNuq5LLDgnhDWQefgNBoMU8GIND3bP6dWKe2GZYaCZ3o3baDRw7do1eDwe+Hw+vPTSS1hcXJROPYzsIWRjMOwWHItGozAYDNje3sbVq1eRSCTk+590gff6DA/r9evXsba2hgsXLuDMmTOSPEbLiLW7VVikWq3iyJEjGB8fx+zsLD766COsrKw8xtjVNeydy15h3ju27e1tfPzxx3j99dfRbDaxvLzcFSoKPNI2Ve1W/Z+CnRoSfRxMX4/FYvjkk08ec/4Non7v1Wo1eRYqFCxp0el0xOlLiLDT6Ug2b6VSEfOcY6ewSqVSXRVD9xufug87nd0yDFeuXMG5c+dgsVgwNTUFk8mExcVFGQfPBy0HdY0J1xD2ACB1k8g4jUajNG63WCy4fv26lO0ddtwk4svlchmfffYZnn/+efziF7+QoAQ1MotJiRQyqVRKOoepHdmIW0ciEbzyyiv42c9+JsEOw5yl3tDjRCKBeDwuRefIjBm2SL+Ew+EQTF9t1kHrXNd1ccQTzye6sL6+LpZTr+/qILQvc9c07f/DrvM0pGnaOoD/HbtM/W80TftfAKwA+E9fXP5LAN8BMA+gAuB/Pshg+kl3HtRsNot6vS5JP4xp7a3URm8zq8up73ET22w2xONxXLt2reu+6mIPo132Gzu/I5PJ4MMPP8Tbb78Nv9+PyclJwVLpCyCDoiCq1+tYXFzEzZs3uxxpB2Xsex2sXksD2D00iUQCv/71r3H37l2cOHECx48fx+TkpGhJ+XxeoC+32y1ZpL/+9a/x+eefC5bbO4+qkFTHob7Wj/gemyq89tprCAaD2NjYEAySJi6xWBWD56Hk4aJGD+zmNgSDQUSjUSSTSdy5c+fAQlM1sVdXVzEyMiLfwYbn3H9qJiTDYXngqfnn83m4XC55rVwu4/r1611Ch/NykH2QTCZx/fp1vPDCCxJ9RScpv4eaPOeo16HebrdFg2RFSGA37Z7t55xOJz7//HNsbm4+pg33O1/9nolr3m63cfXqVTzzzDN49dVXpeCWGr7ZbDalrLDJZMKHH34onbsoSNnWsl6v4wc/+AHu3r2LS5cuiUJ3EJiDY69UKkgkEohEIhKXTh5DqI1VMcvlMj7//HPE43F4vV6xPlm6mHAZ4SiDwSAZxO12u6s+E8dwkH06TLTMfx7w1lt9rtUB/K9D3737s/u+f+fOHVy8eFFqdzA5gUwegEwuIwLo+NB1HSsrK6jVanjrrbdw+/ZtcaD1Mp7e++7FiPYymXd2dvDzn/8cZ86cwalTp2QB2RcR2BUC7GAzOzsr9eD3++795qwfJDII4+ZrjUYDi4uLWF1dxZUrVzA6OoqJiQmMjY1JfYxqtYrl5WVsb29LKGXvBlSpn1BRXx+GCHG9/vrrOHfuHJaWlrCxsYFKpQKbzdbVgxR4FGqqHjq+7vF4MDIyglAoJFCSGjFxUJxY13Xcv38fgUBAzHNd303IYRIOsVcmFbHsM2u9xONxKZXAcS4sLOD+/fuPQVmqRbTXnlDfT6VS+OSTT3DmzBlYrVb4/X4plUsmzzyLcrksORnstcoOUTxXFosFo6OjACB9AG7cuDEwt2EYgdQLbSYSCbz//vv40z/9Uzz//PO4evUqIpGIRCE1m02USiXY7XbUajXp5avrupTYoH/rO9/5DhKJBH784x+LP+hJHJSkdDqNkZEROBwOJBIJjI2NSSFA+gxyuZwwc7VRB+/ndrulciqtS/oCWSpB7VtMOkhtmaem/MAgCER9OJprZ8+exb179yTEKxgMCi5HjNLr9XaZbpzs1157Daurq3j48OFjjH3QvffbBP0sDl5fLpdx9epV3Lp1Cz6fD6FQSJozcLy9iUP9vqf374M6V3o/vxe1Wrtt9HK5HObm5sQ0V52U/Pkq7jnM4d/Z2cFPf/pTTE1N4eWXX8b09DS2t7elvySFEwCJCmGyCQ9LNBrF2NgYHA4H7ty5g0uXLnUduP3G3Y/BArtr/Omnn6JYLGJiYgK6vlv0zmw2I51Ow+fzIRAIiOOVXaQooJiUEwwGRQm5devWnuUb1BIMg+ZS3SP5fB5Xr17F2NgYTpw4AYfDgWq1ikwmA5PJJPHwXq8Xa2trkk/C0tVHjx7F2tqaQFu5XA7RaBS5XA43b97cFz7YS0HqF/4MAPfu3cP777+P733ve3jllVdw9epVEdxkpgxDZQ/jTCaDRCKBra0tTE5O4u2338bKygp+8pOfCMyp3mOY/cnzTwWyUChge3sbPp8Pnc5uiRSWD6FPI5/Pi1XJAAT1fBeLRaRSKcTjcfEdMILGZrNhc3Oza/378Zj96Klh7oOoV/PL5/O4fv06ZmZmUCgUpJ+mruuy6eiM4kYvlUqIRCI4deoU7ty5g6WlpS78rh/tp9EPS1zMWq2G7e1tiaXeS4vu93q//59E6zgodTqdfWOB9yKV2Qx6JvX3Xoy+3W7j4cOHWFpaQjQaxZkzZ3DmzBnRLgEIU4/FYtA0TdLPLRYLnE4nMpkMfvWrX2FxcbHL8XoQ7VIdPz9XLBZx8+ZNZDIZTE5OQtd1SayiM5UFo9xut9QIYnP3Tme3vjxDX3sbS/dj2HuNr9+z0DJj3ZqpqSmMj48jm82K1m2xWARuIUTQbDZx7949EUDRaBTtdhtzc3NYW1t7TAj1nqthGGnvOpBR3r17F/V6Ha+++ireeOMNzM7O4v79+3C5XPB6vRJOzOzrRCKBZrOJF154AefPn8dvfvMbfPrpp8jn8wda69455Xj4+YoIQwAAIABJREFU2eXlZRw/fhzxeFy6WhGiYbQUBaE6J/Rx0KJLp9MCzbCF5fr6eldTdHX+DpJB/dQw994DPmhzkFnPzs5ienoaIyMjyOVyUseCiS3EYAOBACKRCIrFIj788MPHCgXtZ9oOuuZJnm2/w/dV3GsQfVXPclDaj2Gr16m/97qm1Wphc3MTGxsbUo3S6XQK46F1RIy2WCwikUhgYWEBm5ubfZNr+t1/EMQ0iOr1uigO8XhccGFmIzMKIp1OiyVE7L3ZbAokNkiYDvJHcazDWJc8Pw8ePMD6+jpisRiOHj2K8+fPw2KxIJfLdTWmNpvNUsmUTsLZ2VksLS3tmRfwJJomP6f+brVauH//PjY3N3H+/Hm8+OKLmJqawq1btyRAQc38npiYwPPPPw+TyYRf/OIXuH37dhfGftD938+aBiACLxaLYXR0VGoy6fpuiDahtkQiIQ5eFhZkCDGjlehzWVtbEwt+kFJ0kPE/Vcy9l8GrpD4sMz/n5ubgcDgwNjaGcDiMdnu3qw1jWtkQ4cqVK10hZb2TpWoL/aTkQTfEIPikn9AYxPB7v+PLWA+93/fvTfvBHk8yNn6G8BAr6TFvQYX59oL6hqX9LDz+puBxOp2SyahmSjOJhcl29XodLpcLCwsL2Nra2jf5S32WQdBMv2t7/9f1XactBQpr4oyPj3fVOmL5aTLY7e3tPbNmB1k3X4ZoGV26dAn37t3DCy+8gBdffFH6HlNwhkIhmEwm3L59G7Ozs6KtD6tgDHqeQcEWrVYLGxsb2N7eht1uh9vtRjgchtPplNIIR48elbVXBUW73cb29rbU0xlUYqKXZxxkLp8K5j7oAKrUT/PkojODs7dAlDqZe20y1dTpF+3Rbzz9Pj/IIdv73n6MbRhI5qukQXPzVRzMYe79JNcPEpqD1q53//R7rfd71df2mwf1mkajgaWlJYyPj0PTNClwxxBSNvZmTZG1tTUkEom+JvdeAv+r2Be6rkuAQiqVkjLFarGxfjHhe+2Z3nn5KvYrz3MymcQ///M/4/LlywgGg5KEVq1WcePGDaTTaQnVHDSuL6tYkNSyC8TMWfqbDb0JF7LsABVTOtc5ht79PAg92G+vqvRUMHfg4FEK/f7fKylhWKyy93/+TZzsIN7qJ6VhGMkgUuuvDGJUw762Hzw1yIk8zFr2m+NhqN/nerXnvca3l0XY7177rbmqUakMvlarYXV1FZFIpKumOPCozrjBYMDGxoZYlb3aGddxkPDSNK0rFHi/dexHvXNCS6jf5/rloAzrq1A/1zufw4y7l/kx0mcQqUreoO/c6zXCffude3XfqRnx5XK5K4y113rg9/YqGb1z1cvUOa5+dZR66alg7larFRcvXuz7nvoAals9XX9UzlN1VPR+hpPda6arm7M38qPfZiWGe5D2XL8PYvYoa0J/WdprA30Zc3d0dFSadKv3YtMV4JH/hP9zvVVMmsJcrR+kRvaoY+21EIexFsfHx/H222/3fcZhhLCqBfcStb5+996Leq81m82IRqNd3YqeJuJ4XS4X7HY7otHoPp/4/VI4HJZ67Vw/8g8m8/U2iqcA13VdYDigG96l0CDc1Y+x977fS4R4AEgW+SB6Kph7o9HAb3/7WwCDtWiz2Yzjx49LhpxanJ/YJcuqMmSJySz0XLPzEJ0wLPpPaEf1bKuk6zpGR0fhdrtx+/btx8b/+zxQvWN97rnnkM/nkUqluq7ZS2vpp+3S+ePxeCSfgNmArH5IM3O/ManfS3rppZdw5cqVrsJYBoMBx44dk/KvPp9PIkva7TaCwSDK5bL0sGR3qkqlApfLJdgrHVYAunpPMi2dhwiANEznM7NbEZWHN998Ex988MFQmtKgZz0I7adp9iOHw4HnnntOztCT0jAwy5ehsbExBINB3Lp1a9/7DvPel6G9hPz58+eRTqcfKwFttVoxPj4Ou92OcDgMTdOkUu34+DiA3ZBTr9fbVc9HrWDJTORkMtlVOptlU1gSg4XT1NIfqnKi6zree++9PZ/xqWDuQHc/TlXb5muBQAAjIyPSnq5cLksaeqFQkA5Hmvao/CczvZjGy8gFavkMpfL7/Uin00gkEo9hsqo51Kv5kQbh6f2oV1IP+sxeB43v9WOsvenS/bC63u9Uv9dqtSISiWBychITExMyZ2wfZzabkc/nkc1msbq6Kj0hB2nFqrWkzil/+tUzYQ0QZj5mMhmpK8JIF2pSbITNPbK5uSmNHPjdDHm02+1SjhV4ZAnU63Wk02kpd8tsaFXjPgiTGYYhDsNID6rNf1lG/FUy8n7UuzdVGjS/Bx3TQaDBQffYC5+no9TlcsHhcEj9n2q1Kg1mqDyo5ZANBoPUkS8UClJ0jZUvWfq5UqnAarViamoKxWJRCs2p/JDn6D8ELENSGUCvNslWZZws9iRk7DAbPBuNRmxubqLZbCIej8Plckk9l2q1KiU2O53dBiC1Wg1OpxPT09NIpVJdtcvV+x9kkw1i9l+FFtI7L3sx7b2uU+dY13VJ8jl//jxOnjyJTCaD2dlZYd4ApPTAyMgIZmZmcOrUKayuruLmzZtS9bIfE+8d+yBc3GAwIBQKwev1SpNzXdcl05gZpuwLykxKwjSRSASpVAqjo6PSOZ4aFEPRdP1RCWOOjVX+6OAEgGQyKeP6skxPtZB6LaXe61QaFvb6qpnyXkrH10Vf1T37KU9PSoNgESoJVqsVIyMj0nmMZURYPCyfz8NisXQV/2NtfL/fj3K5jM3NTenfW61WpRSz0+lEJBJBPp+XUtx8vmGf7alh7nuZSWazGYFAAM1mU5ocUCvnhJABFAoFqUxYr9dx5swZqcLIyWZndkIzuVwOsVgMgUAAyWRy4CEbhvbDqPf6v997X3aD9jpoeu+haRq8Xi+eeeYZXLx4EYVCAb/+9a+RTqclfZrXMgqhUqlIP9aLFy/iRz/6ET799NPHMhUPOnav14tnn31WCidxPev1OuLxuOCfTACyWCzY3t6GwWCQ0rBc27GxMSnjq7ZYAx7BdcwSJvZNBcFkMkkTcQAyFnXehp13CiG13R/vx7rk/dZpGMa+lwV3ECKGHAgEcPToUfj9flgsFmkgn0qlsLq6KglCXwfTP6jyNKyF/FWOhxo46/InEgm4XC74/X5psen1elEulxEIBEQjL5fL0vyE5SdYRiGZTKJQKEhNHIfDgXQ6DavVinA4DI/HI8+j+g6HoaeGuaukMlNN06ShAuOD/X4/NG23fkMgEECn05G6IjzEDDViZTt2Rnc4HJLUROcEG2aMjY11HephmPqTvq8edC4679k7F3v9P8y9+zmS+XogEMDrr7+O8+fP49/+7d8wNzcnYVx0frE1G60fOjobjQb++Z//GcePH8c3v/lNWCwWXL16tasoVe94Bgkag8GA8fFxRCIRzM7OykZuNptSNIpp2WqkgcVigcPh6GqQsbW1JcXaGJttMpmkYp/K1AOBgIQlejwetFotaW2nRlwMw2TV/y0WC/x+P/x+Pzwej0BFhIlY2z+XyyGVSnXFOg+Du6uvPwlz55g57xcvXoTH45H2eMvLywJZjo2NYWJiQqy5zc3NoWqhfx1EYUnHJvCo6fmghKMnvU+vBU5snE3Gi8Ui1tbWpKQFI2QI9Xm9XrTbbUQiEfj9fmQyGdRqNcmubTabmJycRDabhd1ul31aKBQEa+eeUbs6cXz70VPJ3NWQK13X4ff7xdRhCBlruTNLjvVFrFYr4vG4ZArSHKcDjmV1qfm3223Y7XY0m02JOODBPwiWPojUxbDZbAgEAojH47JB6MRLpVJIJBLSxWWYA7sfw9lL+zMYDPD5fHj33Xdx6tQp/MM//APS6bT0v2QEk91ux+3btzE6OgqTyYRMJgOj0Si4dKlUkmzFN998EwCkzko/3F0du3qA2AmoXC5L6QjGC8diMcTjcVQqFSwuLsp7jUZDNCdmHnu9XiwsLMDpdCIej8tcr66uSrMFWmw+n0+YMLMFWXe/d6y94x0k+K1WK8bGxjA1NYWRkRHR2NRWbDz47ApWrVaxurqKxcXFrsJxw6z5l2FmJpMJ586dw9mzZ+H1etFqtTA6OopQKITV1VXpRTwzM4Pl5WVsbm7CaDQiHA7j9u3bT9TXsx8NqyA5HA7EYjFMTU0hGAyKQletVpHNZrGzs4NMJiMt61Rn5FdFrF/PqL1Go4F0Oo2pqSmsrKwI70gkEhgZGZHqr8xtyGazcnZcLpcoLYzXZ/35crksXbkIH1OwAYMzZ1V6aph7L5akHnqfzyewC7PyqO0yE5VJAs1mE5FIBIlEAuFwWDR4FhtiI20WdqJ0ZUwrJxgY3vzeD0N1OByYnJxENBpFp9OBy+USM5/MhY0eKpUKtre3MT8/L82qVTqo0OnH4DVtt974a6+9hueffx4/+clPpL0Xq925XC6Mjo6i1WohGo2KwweA1CPX9d0CWel0GsViER9//DHeeecd1Go1XLt2TSodDjOPJpNJLCpqzcQei8UiRkdH4XQ6JbqJaftTX9Qop2Zps9lgMpnw4MEDbG9vw+/3w+12y+dZhpffxaqGhPjY6tDtdguWT+Y+yMHKvz0eD5577jk888wz6HQ6WF9fx9zcHHK5nBxQWmy0MGltxGIxTExM4MGDB5ifn5cs0P209id1pGqahtOnT+OZZ57Byy+/DE3TRCtn4+6FhQWBGyqVCvx+P773ve/hF7/4BRqNBmZnZ79y5tk7RmC3n8DRo0fx7LPPiqXOUsMOhwOBQAAzMzNigZfLZclc3drakrT+J3HO9vIjWoqsYcXaRQ6HAxMTE1LvStd1ccqn02nEYjGJAut0djuhUbkjepBMJrGysgKHwyHhzOFwGOFwGKurq30t8b3oqWHuJA6YjNzr9QrOzocrFovSVWdmZgZOp1MK8BuNRsRiMdhsNtjtdpRKJWjabhTIsWPHcPPmTamIR9iGmnyn00E4HEaxWHys5vNe2kU/s5zPEI/Hcfr0aWHSrN3M+1erVekLy03h9Xpx8eJFLC4u4sGDB49pSMMyzF4YhP+bTCacP38e3/zmN/GrX/0KjUZDIBg2QbHZbLJRqWW6XC7k8/mubkiRSAS6riOXy0nlwddffx3ZbBb37t3r6qPZK2BUwchG18TsTSaTVPakpZZMJrGzsyPaYz6fR7FYRCQSwfnz53H9+nW0221xumaz/3973xrb5pml97yUeBFJkRQvulE3W7Zky3bGSezYuSeTdGd3JpjBLAZBB0U33Q6wfxbobrFAu9v+WPRfCxS7nQLFbgedbjszi+m22UWTSSaTjDNJZj0bj+NbbPmq+4WiJFKkeBFJSRS//qCe45c0KVF2EtsqDyBI4vX93u99z3vOc55zThzLy8tSH8Xr9aK7uxt2u13qgLNBcSQSQSgUQjabRTAYxLFjx/DLX/6yRInyd6W14PV68fTTT6O7uxs3b96UqoDpdFqYO4QPDcOQe05q5szMDMxmM/bs2QOXy4Xh4eGSoHK1NXe3lntbWxuefPJJDA4OYnR0VKBLKhSuV5YftlqtUuTs+eefl7gMqYD3IpUgOj7e3d2NkydPwufzIZ1OY3p6uoS+Si+TPWz5WVarFQMDAxgcHMTi4iIuXrwoB5W+9nbK4CE7K5FIYH19XQKg9LatViv8fj/MZjMWFhaEnTU0NIRr166JLnK5XFI22+FwSGMWPduVgf6+vj7MzBRbU+v5PNvJA6fcdRxNKYXW1laJQtMVYv/H5uZmdHR0oLOzE+Pj47KRMpkMIpGINKjNZrPo7+9HW1sbOjo6MDk5iUwmIwwJpYo9QxsaGqTAP8fCzbxV5muljDuz2YyhoSH09vYKVTCZTCKVSklaMimGQNG6Z+nX5uZm6Zxjs9nw6aeflihJfWzVxlVJCXFB8/A4f/48crmcFDpqamoqoSZyTkgtXVtbk+QN1qA2DEPuEavjzc/P4+mnn8bs7KzUz662efgZ/B4ePmyoEQ6HYTKZcPHiRSQSCVGUhNFmZmbgdDoxOjoqHh3hnZWVFTQ0NEj1w42NYgNnconpgdCAoIfHvq36oVotZgFA4hYulwtnz55FU1OTUNoIJQIQWi57BiulBIJKp9OwWq3SeenYsWMYHh4u4UPr36mPa6fS2NiIAwcOoLOzU7Dc+fl5pNNpBAIBgYvYnIXlss1mM+bn51EoFHD8+HEkk0lEIpF7hmfoxeqGHcsMf+UrX4HJZMLk5CQikYjMExlPXF+JRAKFQgHt7e2yhkltDgQCeOmll3Du3DmJ5+iJbrVi9YQylVKIx+MAIB4sjZzR0VEsLy+ju7tbGH3BYBDt7e1ibCSTSaysrMi6MwzjjtaE4XAYhw8flgNEb0Cjz9VW8sAod33j6H8HAgGhszU3N4ulm8/nsbKyglu3bsHtdsNms2F1dRXNzc2IxWIYHR1FMBiE0+lEOp0WxcEJpXLiTeaCYqH/8o28lXLnwcMJN5vNeOKJJ+Dz+QQuWllZkR6vvEZihgAkZpBOp5FMJoWDPzAwgPX1dVy9erXEwqh1U5dDOA0NDRgYGIDVasXExARsNhtaW1tFaeoekmEYEtBZXl4u4X8zI5QHmdvtlo1y8eJFfP3rX0cgENiSxqVfDxM4ePi1tbVhcnJSLBhyi4mLFwoFwa6TySTa29thNpsRDofR2NiIgwcPYm1tDW63G11dXUgmk0gmk1JBkg2V9XLAhlFssmEymbCwsFCCvVcLZjU3N+Opp56CzWbDpUuXJA7E9eB0OmEYhkBUesYjYR/CNI2NjaLss9ksnnzySYyNjWFkZERghXKYbafKXSkFv98vc6I3QSdkWCgUxEMjvZi101dXV6X/p9frhdfrLamTfjfCdUQxDAOdnZ145ZVXhEM+NjYmXgXjI0opKdLFtcuUf5PJJAf2wsICfD4fnnnmGSkjvF1GerUgOaFVwmarq6tQSqGvrw+hUAhHjhzB2toaHA6HFFlrbW2VmKFe4plNUyqNxzAMoRfrh99OPLYHRrlXkqamJrjdbsG52N6NkWo2lWBiE99D9gMAsYIbGxuxsrIiUE5jY6NkRzocDkkjLhQK8Hg8dxT23yrAqScsKKVw9OhRtLe3C/+VLjmVFDc5qwSura1J0Jf9YJeXl7G6ugqLxYITJ07AMAxcv369JMW5WgXBahCCYRjSAX54eFhoVuzxyWsxDKOkgTQ3PjcQDzNaTwxaM4nIarVifn5eAtvlJUwrCbP6mHdA1g6DV/oCJ0WPXs/GxgZmZmawf/9+tLS0SClYZrhyDliwiYaC0+kUrJ2fw+D6yMhISZmDSrh7Y2Mjjhw5ArPZjBs3bkiJYaWKfTLX19fF27RarTCM2w1FGCvSyQF6sIyVGI8dO4aWlhacPXv2jpISd4O3K6UkTyGZTEpPYjYOZwN6zrPeP5XkBTbKaGtrg9frRSQSuWc6pi4ulwvf+MY3kM1msbKygqtXrwpbTqli5U2HwyFZnawI6vP5pCosm2bQ+FhdXUVTUxOeffZZxONxhEKhbeewHNZ0Op3w+/3i1eXzecRiMfT29iKXyyEUCiEej+PAgQPIZDIC+dEQzefzaG9vx9ramvRMdblcOHjwIKamppBKpeTACgQCEiMkBMRxcC8+NJh7uburVDFxScfcCQ0cPHhQosnr6+vCTSdtz+Vy4cCBAyVRaPau1Htdss+l1WoVa47BLbp0252U5UprcHAQ+/btQzabxa1btwRuYAo/T22yfkwmU0k/WG4ewiJcxF/+8pextLQkzT6Arbvx6GPT/29ubobH48Hw8DAaGxvh9/vlYMrn86JEdRogYQFao/qGp1AhOBwOxONxhMNheL3ekroc1axNpRR8Pp9YkouLiwIJ8BBhNvLa2todVQvpld28eRNdXV1SMoGNXFZWViRmwE433GAsZcENazabhaK4lcIymUzYu3cvgsGgcO3z+XxJwhXjRrTcGb/g2HXIi4eAnpK+vLyMK1euYHBwEAcOHMCVK1fumWfOoDnXDmM/3Fuzs7MIBoNwu90SlMxkMnA4HHKN9IQdDofQlLcqA7wTMZlMOHHiBNrb23H9+nXE43Hx2riWeJ9YDoMQbTAYFMOJHbaoN+gV+f1+nDx5Em+//bYc6tXGUU6WaG5uhtvtxtTUlNwrGpvhcBgvvvii1O4nzGWz2eTw46FPr9wwDPh8PhQKBfj9fiEvPP744/D7/dK0/Oc//7lcV63BVOABU+66ZUSslBadYRiSWs4kpWQyib179+LatWvCV6Y1zDo0PLUXFxcxODiI9fV1oUwFAgF8+umn0n2GCTvBYBDXrl0rYc1sNZkct9/vx6OPPirUNn1DkGdNy4hW+cbGBlKplCgk4HbSDOEBwiOPPvoo3n333RLrfSu8s9xyN5lMAhXxu4n5KaUEQuJBQ8+Ii4rWEOuU6wlA/D6didTV1VURaiu/7yx8FQ6Hha7IfrOU8kQijoc1b5qamhCLxYRyZrFYsLS0hMnJScHhOzo6xBPgdQDFpsf0QABIhvNW7npvby+OHTuG69evw2azyYHNtUCcnfALmzNQ0eiKQ1fsHAfxelLnHnvsMSwsLAhxYKs40FbCmFI6nZY6KIxjkYs9MTEhdU0ikQieeeYZTE5Owu12C3wJQEpSUBHdq1D5HTt2DPPz88jlcojH48hmsyUlJThniURC1mtbW9sdhyp/Z7NZ6ac6PT2Nvr4+idOVw1zl4+FvpZRQZyORiHw+e0a0trZKqQAajIR7x8bGcPXqVfj9fgQCAbS1taG9vR3z8/OIRCLSR9cwDDzyyCPweDyYmZnB6OiocOLdbrccZJX2USXZVrkrpboB/ABAGwADwPcMw/iuUsoL4G8A9AGYBPCqYRhxVfzm7wL4KoAMgH9mGMaF7b5Hn2TiW319fejp6YHNZsPU1JR0HY/FYuK6MpuO9MJ4PI5CoQCHwyERbMIHmUwGS0tLaGlpkRopuVwOsVhM6qmwKFVzc7O079tmfuRGP/XUUzCZTJidnUUsFhNKISEXAKLwycEl9mYYhhTAoiXF12UyGSQSCXR1dcHhcEg5gO02d6XgG6EPKiMGJ3VcXGcScKHydfQs+Bo9l4Dz4HA4ZOPze8vHpbu7hw8fRltbGz7++GOYzWZhGOiJXkxU4QZmUhrHwTo0ZrMZgUBA8HNa9cQ72Yy8ublZ+qsmk0mk02mhP1ZLwuJjPp8PL7zwAjKZjCgXu91eUh9J/+E46aZzrvg4rTp6JxTeq/X1daRSKRw8eFAO+7uFZNrb2+W+k2rKg9NqteKVV17Bj370I8zMzMAwDBw8eBAvv/wyvv/97wu8aTLdbiNH6312dnbbRiO1CDunzc3NCe7PVH7CRH6/HwAEU+d+1y1bGkBkJNF7Ylyru7sbExMTVeeQxhMNAeD23o3H4yUlLLLZLM6ePStr1OVyyX7JZDKYnZ0VlhzzHSKRiCAKLH9y9OhR0RNjY2OIRCKIRqMCf01MTJSMbzuphVOTB/BHhmEMATgJ4PeVUkMA/hjA+4Zh7Afw/ub/APBbAPZv/vwegL+o4TtKFmyhUBAmTFNTE1ZXV6XJ7PT0NKLRKOLxOFwul2Bp7KUYj8dFIaRSKdlMSimplMjuJ7Ozs8KPXV5ehsViQWtrK9xutwTYgK2VKK3LlpYWtLe3S2IP+dZ2ux2dnZ3o7OzE9PQ0lpaWhAnCxeL1ehEIBOB0OrG4uIhoNFoC0ayvr0tavc/nu8NdrCZ61qv+QxyPKc98HaEVfXNwkZILTmXE9/EQIpWUUBlw2/rWx1s+bovFgoMHD+Lq1atQSsHlcpXALnqZZ1q1ujutQz2E3iwWi9AwWXqA+GUul8Pa2hoikQhSqRQWFxelpjots2rcbRoeQ0NDcDqdmJiYkM/kXNFa43WTkcVNS9iGa5Kvo5TPFfFtGiCMIdRqvemfa7PZ4Ha7hTlEuJBQVSqVwvj4OAYGBuDz+dDa2oq2tja88847JYe71WqVhL/BwUGJYXwW0tLSgtXVVQneOhwOaZvI8ZTHfejB8bAmjGe32wFASAzRaFQgt87Ozm1LJNOT5b7goZjL5ST5rLyqKPUViRHJZBI+nw/xeBy5XA4tLS1YWFjAxMQEhoeH8cknn+DixYswm83SJlI3boBirKijo6PEmKpFtrXcDcMIAwhv/p1SSl0HEATwDQAvbL7sfwL4EMC/3nz8B0Zx151RSnmUUh2bn1OzEI6Zn5/H1atXpVM4aVEWiwVdXV0Ih4sfS1oUKweurq4iHA6jo6NDOLyxWExKyIZCIXR2dgr1i6nBdKd4KtcanSZ9bmFhQTZvIBBAe3s7DMNAOBxGOp2WCHp/f7/UnqDiuXnzprAlvF4v7Ha7xAXS6bRAP1NTU1suSt0q1h8jhMIADRW1YRSZO7TouXgymYzUluZnEUIixEALh8+zciRZMjrlrJL76/F44HQ6EYlEsGfPHrGq9XFQYRJKaW5uluAaFSCr7RGvNwwD8XhcsGFav6urq0KDXVpaku9njKc8iFg+rw0NDejr60M4HJbro2GhW456nIFxC1qQhBkJIdIY4eHF0sSZTEbc9fX1dfh8Pvh8vpL2cTsRn88Ht9uNgYEBiSkwMMiqhqFQCE6nE0eOHJE5S6fTJYaUyWTCI488gpGRETQ0NODQoUPSB/ReA6tsEs1yuU6nsyR7k4pdD/DTiqai12NavEbqBsMwkMvlsGfPHtjt9qr9assDlgx0kvWUSqUEFdAPcwaigaKyT6VSSCQSkicAQEqicKw2mw2xWAwDAwOS4EQMfm1tDW1tbXjmmWewurqK4eHhmiGwHWHuSqk+AI8C+DWANk1hz6MI2wBFxT+jvW1287Gqyl1XRvy7ubkZ+XweZ86cwcTEBDo7OzE2NiZsmGg0iosXL8LpdAoXnDStjo4OwcLC4TBSqZSwIFKpFMLhsLjUsVgMmUwGc3NzUiciHo9L8lMtYrFYcPToUayvr8vE071eWVnB8vIyQqHbwrHCAAAgAElEQVQQAoEA8vk8wuEwnE4n9u7dKzg8+bGEEUinYuBvcXFRAnIMEpUHKrX7dMehpP/PlOn9+/fLOKl4+NpCodjSLB6PIxgMwm63S1Pq48ePlzB++Ln8LJ2ZVClJRJ/XQCCAWCwGp9OJVCoFm80mln9DQ4NY0rxeKlF6CnyO7B673V4yV3wNLSluGLr0KysrYpmlUimh2lVrdkLoKZ1Ol2C8/KHi0S0vWpm0jtfX18XLIAWWBxm9H9IpCUWtra0hn88jEAhgYmJix5Y7UDxI29vbEYlE0NzcDLPZjKWlpZJr4JjJ0c5mswLFMOaSz+exsLAgcGFHR4d4SIxb3a0w25xWLmnQDOrqmHtDQ4PEjXK5HFwulxxahGAZ0+JBSlYQvZVqUr5eWXaA5XeXl5fh8/numDcKYyak+PIQ0pU/9xkNIv69b98+9Pf3Y2ZmBuPj4+ju7sbq6ipefPFFbGxs4MKFbVFuADtQ7kopJ4C/BfCHhmEky6xCQym1IzNCKfV7KMI2Emyi9WIYhpzYdGMNw0BHR4dUYuvp6ZETnpssn89j3759wohpbm7G3//93wO4XVCMVMdCoYCZmRnMz8/DMAxpCPG1r30N0WhUXHqmNFcTWmkNDQ1IJBLSLHdtbQ3xeBwtLS3o7u5GNBqF2+0WXjC7ojudToRCISSTSVHaTU1Nwo9mQsnq6qqMSf/eamOqZL2TLcNNQToW38MNwwPD6/Vifn4e2WxWEmxYxIvfT6tJT8yhhcQxVxoff7vdbrkH/Cx+v97yjVYYlSdw2wLigUW4holCdJ31g420Q97XxcVFtLS0SJLMl7/8Zfh8PkkmqrBuJfGLG5hjpZXIAxq4zbrg9+qxDfK1yTOnta4HzQgXsnuR3++vOUNRF6vVCo/Hg0OHDiGZTIp1yMOPiobKlYF0Bt85prW1NdjtdmFEKaUEyqRHdS9CBUcmCqmEeoyCoueMLC8vY3Z2Voy46elpKdvMtU2vT2cxVZNyg8RiscDr9UqhN1Z95LgqwWv0iBmz0tcwUDReMpmMNEZ/4403ZL4DgYBQVMfHx3Hx4kW88sorGBoawsWLF2uay5qUu1LKjKJi/2vDMP5u8+EFwi1KqQ4ALIAdAtCtvb1r87HyyfsegO8BgNvtNuhycYIcDgcaGxvxwgsvwGazYWRkRMpg0ipiwI4WmFIK4+PjwoiYmpqSVHTgdqKQx+OB2+1GOp2WE35oaAh9fX0AIBzVWjB3WpR6QwtyljOZDOLxOAKBALq6urCxsYHOzk7YbDaMjY0J+0fHkE0mE7q7u6XIEBc5rRFim1stzPKApX4Q8OAhdqhzZvVgFANuXV1dgiuynAIXPu+X7mJSMdhsNsnMrTQuis1mQzwelznkHPAadXom55sKAIAkkdAooMLUMVn9/ulBPyoLQjOsnc0Ad6WAtD6HxEk5BnoahFHoQXFTcxykZvIaTCZTyYEA3K45pMNixJ/J89+JuFwuyZKkd5RIJGTcAEqKUxHm4NpgTgEfI7TlcDjQ19eHYDCIqakpRCKRHY2rXJjoZ2wGxJlRTLiUQkhGX7/j4+PigRKvJ5uKBofOouE1VRN9DdDYHBkZgdlsRktLC5LJpDxf6cDQYc9y+i4NAnoQPGC5lufn50tKQmezWSwtLdVE8qBsawKo4ui/D+C6YRh/pj31JoDXNv9+DcAb2uO/o4pyEkCiFrydLh+VpcvlEveVAUa6OeSWcoK4WYibMlh0+PBhSbEuTx5hgpTf74fNZkMgEMChQ4ekVoUegNx2EjdvajqdhsPhQFNTk0THWQnS5/MhGAzKaa278jzVLRYL9u3bB7/fj1AohJmZGUxOTiIajUrwRrsvVcfDRalbePr1ENdnCzDdLedruaj0YmEOh6OkLjW/Q7da6MrrLIWtxrm+vi4MId3K1b0IKnNaMq2trYI/8yCl28yMRSoh3WXWP5N/WywWdHd3o7u7Gx6PR8r+VptffcPyNUyiKW+bxnnSDy1i9DoLiM8RjuBc6/z+XC6H5eVlOJ1OMVJ2ImQSkT7IvaOXYgCKSoRlHgKBQEkZWx3npjdbKBRw8+ZNWK3WEsbQ3QqLrLG2EIkJ1YLOOuyns3nsdruwgVwuVwmlurz0x1bCeWant+vXr0uGd7nFToNH30d8zG63S68A3fjQYR2uW90g4+eTNbWdx6FLLZb70wD+KYArSqlLm4/9GwD/HsD/Vkp9B8AUgFc3n/spijTIURSpkL9by0B0RUoGyfr6upxWtMa5cbgZgNsNkVtbW9Hf3w8AEsBYWlqSha3zj/V2ex6PB+l0GvF4HHa7Xfpv1qLguUl0dgtQXIBcAFSE09PTMIxijRlSppidarFY0N/fD4/Hg2g0ivX1dfT09AiGyO/Q3bpaxqbj8rRiuCgJFXAMAMQK5/ubm5sxNzcnQWm6vVyEtPKolDmnLDxWHpgql2Qyic7OTlEgtNa5DjiX9OwcDgfcbjdGR0eF0UGeOusKURobG0VZcpz6xqP3R8uwvb0dS0tLJfxnXXiNDN4Sv+f8kSWlK27ee25M8q0JJdHzIWdaKSWKiTBIJpORUtV6gaydKHjuKXpKNEZ4XwkpZbNZdHV1CV7t9XoF7uCYc7mcxATIROJnE9a5WyEcRs+VrDXWCaKxQW+IFi/1gn4AAbdjXzy8SJVl45GtoE39OavVirGxMakJwwqfZNPo+D3ZU1wvHBfHUt4cm+PUA/B8jtdpNpuxuLgo3l4tUgtb5jSAambiSxVebwD4/ZpHoIm+YInBsmKdXkaAp5neYs0wDNy6dQstLS3w+XxS4/njjz8W144KSY9wE35gVTbCEOXu1VZCa7WpqQmRSARNTU1itZNBwyDKysqKYMyBQED6v/r9frS0tEg9D24kv98vvGtCHdspzErj5dySgWE2m4UaVh5Y0t9PC5wLTPeCGOugVaeUwtTUFAAI00fHmHXoh8LaGwya6Qubn0kYwmQqVshjoHZxcRHt7e2yJlZWVoQRw1rkuhXNw0gvGU1qYTabxZ49exCNRquyEbjxqNRoIDD7lcFvbnbec/1aUqkUPB7PHfkBPNSYjakbFixpfPz4cWnoUO0+VxPi0wAkWS6Xy0l8ifXP9eqQvB9kc1DBc416PB6ZD6/XK/Ghu8HdaYSk02msrKwgGAwiHo9LAJoHMb9Ph7vMZrPsccaTdEiJ7BnWKWpra5NkwK1EV7SkN5LFMjMzU+J9s+aSblA1NTXJe3kg8yDVFTl/yg03XRjT6+7urjTUirLzyMznJPpEcgGx0z054cDtOi7EImk9sQb6hx9+KCnlLNa1vLwsNDPiWPqEspAYFbTOANFdwGrj5uYgr51WIhciI/SGUex6nk6nJVmG2CetCH1DMxBD64iVF7ko74Z2xkxEBi9HRkZKKHnEf/n5jAFsbGwIZZAWiY7XUsHH43HxRPRNXg4T8bFUKoWWlhap466zYDgGzh3nT2/mYTIVMxDZTILUUUJvegVBfX4pZMfw3ukKuVx4jeUbmeNjA+SGhgbEYjGx6qPRKHK5nNQXSaVS8jcPNdIIOcdcV8S+qZB1130nwrWvH26kAnK/6S0o9+7di8HBQfh8PlgsFgSDQcmc5Zqkt8r1TR743Qjvy+rqKkZHR+XwZJ4HS+tSsXONMKFNX7t6nR4AEnuh4QcUk4QqMbnKhfO8srIivQEWFhZKLGs9RqR/p8fjkb1FLL280ii9yYGBAZw8eRL79u27g1rJ63S5XCVtLLeTB6b8AEW3sBYWFrC8vCzcV07k3NwcPB6PcG71noR6FchcLieBTB3LYkVALkbe+EQigeXl5RKlVIvry3ICVqtVFLfdbofL5SrBeMmgIQ7Huh78X2ctsPIeKXCEJebm5moeWyUFkEgkxJLVNxCVJQsx6Xg6szqZbatb33qVSAahqaAJO+gbqHzMzBJm2YBKyWO6Jc/AGCuEplIpLC8vi5Il/Mb/rVarwDZ0jymEpVgjnlDIdvcaAPbu3SslXGmN6YlBxNoJw9FaY5IXlQUPUo6bc6RDOowz0dJncs5ORK9KyftCD4cJSVTubrcbX//614WU8Itf/EIOLZZ10Hvr8gClArtboSK7ceMGnnvuOfGAabXr646YOddwOczBfUQvhB5ib28vrl27VpUNVU0YT+Ma1AOz/F6Oj7WKaNwRDtXjVDxsDaPISjt+/LgcHJFIpATS5Hf09/fj/fff/0wx9y9c6PYyeaetrU1cwmg0CpPJJEFLLrimpiaxoM+fPw+gmMrM1/EGEFaYm5tDb2+v4KDJZFKK+ZDloS+m7az35eVl7N+/X6pX6hY/rcFcLicnNa1VWhVkxPAg4ucSjgAgVej43HbChcG/eW1k4BhGkZEQj8fh8XgAQPo5MtjGjjddXV2Ynp5GJBIR5UUuO4OshGR4WFBx6QEn/X8qGKZi60HVSgcCNwULRTU2NgqdkxCYHiykZanXUNc/r729HXa7HTdu3BBONXvoVoO2aLm3tbWhv78fly5dEmotrXla8Tzg+vr6sL6+juvXr2Pv3r04dOgQLBYLEokEFhcXRdnqwVpeLz0Ok8kkdFnWFN+J0DtgZysekvqBxAbypInymhobG6VeEAu6LS0tiZXM0g/0pO9G9EBhKBSSIDo7p5EGrMN7a2trkmWt1/XRlSLXQD6flxK758+fF0Vbq3CtU38QctHHz7ERkqXoTCmgdD80NDSgtbUVGxsbQommZ0RjiaWqXS4XxsfHSz5jyzmt+eo+Z6k0UYxm08Km0m1raytJDCDupePwVqtVgmV6JFr/PlrvTC5hsKq8Pdx2E2kYxdrLvOF6tiKFG6WtrQ379u1DT0+P4JRcmFRcAOQ6GKjzer2Ynp6WOalFuVe6BmbrMYZBRU8FwjnK5/PI5XKYnZ0V+mUgEMDMzIxY9kwgKxQKSKVSgt8Ct+t+bDV/VITj4+NS+A24Db3pm0JXeEw+o5Knxc3m5yy3S4jI7XaXuPL8aW5uFjpsb28vlFIIhULbKncqvr6+PnR3d4uCYWa0/j0cdzAYRDAYxIsvvojjx4/j6NGjGBgYQGdnJ/bs2SMe5fr6uhgBQBEfz+fz+MUvfoE33ngD4XBYeg6Uw1xbSSqVQiwWE8+KgVoaDIQy+b1sfMO5ICuNGeC856lUSownBq/vRvRDjTAW1wG9BD1Qy0OP5UWA24cha0oZhlESS3A4HLhx44Z0ZKKHVIusra1hYWFBkr90qFD/AVAS19MNmXIjhwdWMpnEhQsXMD8/LxAyvXVWvnz55Zdx4cIFqb750Ch3XjgniKf42toaent74XQ6JSipW2A6dMC/ObGkLpnNZgkE6lQ7p9MpCkKnXbJQl/4d21ntALCwsCBWI2+8zsGlO93f3y8p5B0dHQgEAlJoSGfwcJOvrKzAYrHA7XbLqb0dTlg+Nv3vQqGYvOXz+QT/oxVDjFhPk29ubhZPpKWlBcFgUJqIFwoFUe76dQIoaZmnK+ZKMjk5iY6ODmnUoY+VVhcVpc7vJrxBrJrQFovAAZBAOT+H7nE+n0coFMKFCxcE4rt8+TKi0eiW99wwDHHpzWYzDh48KN4arS2dRUNvIpfLCUddD0Cn02lcuHBB6ocMDAxIchGZJ+Q9z83NIRwO32E11iIM7DOxjBam0+kUphK9Y2Ztb2xsSMN2esc8DPk/g6iMG9UKGZTPqf73ysoKJicnZa1xzFTUNITo2es5AzSIOG98zO/3w+v14syZMzvOEQCKa/HWrVvo7+9HoVCQNor6IV5+7eX3SD8E9MNnY2NDEipZU4cePvWE1+staftY6fPL5YFQ7hTdNeXid7vdmJycFA6tYRhicZS72Xx/V1dXCX+YJ6h+gBQKhZLyp11dXXIi6rWpa7Xe2YeTJQMI9bCbD+GW1dVVCR5aLBZhyeiB3EKhIBTQ1dVVBINBTExM3FF/eicKXsetZ2ZmpH6LfhgR82eRsGQyKTkA7e3tCAQCYi3pmw2AlAEGbmcDl1dXrIS7G4aBRCKBZDIpVRsNw5A6QqSQlWObelYyrUbS0ug2W61WaWumB+AYjJ+amoLJZEJnZyey2SwuXbq0pSXH749Go5IRy3KvXJtcv8TzA4EAent7RWmTJBCJRCSOsbS0hJ6eHrzwwgvo7OyUVH7CdvRSSdfkWt6J5Q4AkUhEasjQq6XXkclkJIaxvr6OTz75BKdOncLNmzelMQq9EwYL29vb5aAhs+WzkEKh2M2LDVW4JvVANA0Pem26VUySAve6x+OBz+fD3NwcxsbGajaOymVyclIML71WjW7IlXuaFF2h66+jnmA7w8XFRfFQWPrhqaeewrvvvistBYGHGJbhpqWiZLaezWaDz+cT9gNPTF1xxeNxKRJGC1THnjnBPp9PFFI6nZam2gyOUvj+7ax3BoJ6e3vh8XiwsrIiNEMdv2czCrp2pHDxe2j5ut1uuFwuHDp0CIZR7M1Yq5QvLH3BGYYhrcvIPlhYWBDlyR9amDxU+TwVt54dTByaVhPT02llVRuXfr+Hh4cxNDQkmyaVSsHv90u3KLKcdKVOhccED2LcOuRAOAG4XS+cGDI3Tk9PD86dO7dtPINraGlpCYlEAmfOnJHeroVCAR0dHZII1dLSgpaWFvT39+PZZ59FMBiEYRhS24gNZjweD15++WU88sgjiEajiEajopiYL9DT0wOfz4f29na0t7fL/dipcl9eXkYkEpH7yGRArnsG7fm5rJ9DnJm1ygGIF00cfHFxEYlEYkfj2UpCoRCmpqakYTh55dwrOmOMeoDF9bgWCR/SOz59+vQde7sW4b7JZrM4f/48nn/+ebS0tAh0rFvwOiNPh5rKDUvOoclkkhaWkUhEMlNXVlawtraGI0eOIBqN4sKFCzs+kB4Y5Q6UQgdMQ45Go0K1ouVFy01/D092ZogGAoESDJGfSwWq44SkJTKAqLttusLbasxKKUxMTGBxcRHBYFD4yrlcTgIjXGwMpjH9m3EBQiOsp0GL7dNPPxXIphbRx1vOIACKinJubg4dHR2wWCwIhULSDJs/zILkZuEiZj0XekRkebBpuVLF7OKbN2/e8f2VxsiDb3JyUlqUra+vi/vPA4MBSlqOSqkSbjxhF2Zz0utgYlMoFBIYJxKJwG634+DBgwgGgxgZGcGnn356B25aacwAxMoNh8OYnp6WMdDryGQyAldEIhHMzMxIn1nOGa3jbDYLj8eDUCiE8fFxTE1NSSIWLXWuIa/XK5b3VnNbTbLZrCTvWK1WoVdSqXP9cy75vXqwstwIsFgsWFhYEKv6sxB+/0cffQSbzYaOjg4J4rMA3Orqakm1VHqRXDvklfv9fvT29uLChQtSQbYWqTa37GC2f/9+5PN5JBIJ8WpoTJTTrnUjVI9t8Uffl3rspru7G319fXj77bfvgJIeKssdKIUOWCGQaecssUn8WU//5Y10uVwStae1r0fMlVLCnKCFkslkEIvFpDogJ7bcYt/OSiJ+du7cOeTzeQwMDJRkqvFQIhWSBbh4Q2kVcZGkUimphBmNRkus/1rdyvIFoCvU8fFx6UxktVqxuLgoOLsepNYtE1rHDMRSmY+PjwvUQ5y0Guuk0kHJQ/ZXv/oVgsEg2trakM8Xu0CxCijZCtwwtMzpGuuNnpmAAxRr13R2duLAgQMwm83SaOHw4cPSJPqjjz6SzVMpAFZ+n5lD0dfXV9LwmH1Fn3rqKSmbkU6ncfnyZZw9exbhcBivv/463nzzTbzzzju4evUqJiYmRBkx61WHGBKJhCTGOZ1OUbblAftaZGNjA/Pz8wiHw0JS0AN3TBJilyaWqY5EIlKrhfuDh6zNZsP169dl7J+F8Lri8Th++tOfor+/H06nU0gGbK5Chc77wWDq6uoqbDYbWlpapFfA1atX7zCOtpq/SmuU8YC33noLTz75JOx2uzB6uI8rKfitcHl6/VzXyWRSCg4eO3YMP/vZz8Sj3G6M5fJAKXeKYRjS1svr9YqSIL2ImJR+4lEplSs/3QItV/QmU7Hwkc1mQ1NTExwOBxYXF+/YYEBtyh0o4rHXrl1DQ0MD9u/fD4vFgrm5OVl8xJHpZtKFbGxsFEt1Y2MDXV1dSKVSuHXrVglWXWsMoDzwUp79lkwmMTs7i+7ubuHnX7t2TTYpFT2D21SiVMRLS0tYWFhAKBRCIpGQGj0dHR2YnJwsSQSrNB59nPyZmZnBL3/5Sxw4cEByG2KxGBoaGjA4OIi9e/dK7SDgNgOJipmWJi26fD4Pj8eDXC6H0dFRsdiPHj2Knp4eNDc347333kMsFtv2ENKVPjOSW1tbxduiu53P56ViIuecDWQikQjW19cFeikUCtL5izAelS3XxOLiorSZIxzp8/lKGqHsRBYXFzE1NYWJiQkpNUErXa8L09jYKPAdA6dkgensrnPnzgm0d7dSvjb0NXPjxg389Kc/xSOPPILe3l60traKR5zNZtHR0VGS2GgyFXvbdnV14dFHH8WFCxfwq1/9quTg2Wm8QvcwDaOYCf/xxx/j1VdfhcPhENaVnpPC35wnKn79/nKvM74Vi8WwtLSEYDCIr33tazh9+jRu3LhR1ZDb7t4/UDx3/SLGxsYk0HnlyhX4fD6xhFn7RVfATFgAivxlFsUCbteX4M3Rgx+sK+JyudDc3Cwn/HY4+1YyPj6OQCCAzs5OeL1eJBIJgT3IzW1uboZhGNKOT89E9Pl8WF5exieffFJCudpqvqrNZ/lm0bnYly9fxuOPPy4wjM1mw+zsrNAH2cyZkJhhGMKMIPfWYrGgs7NTGmNEo1Fp0aaL7nWUj5/B80KhgKtXr8LpdOLw4cPweDxyMI6OjsJsNkvXKjIWotFoCRectbGTySSWl5cxMTEhB3pLSwsGBwfh9Xrhdrvx3nvvYXR0tGSeqkFaNAwYnF9fLzZiZy2ghoYGqRPOdWgymRCNRqXPKGt06+yUo0eP4uDBgzhz5gyAYgbxvn374HK5kM1m8emnn6K1tRUej0eChw6HA21tbRJw3Ymwq1OhUMD+/fslpkUFabfbsby8DABS3ymXy5UUkHM6nXA6nQJN8bC7F9HXqL5mC4UCzp8/j9XVVXz1q19Fa2srIpEI0um0UHFJnWTSU2trKwzDwHvvvYfz589XLGBXq/dL0XVNPp/HqVOn0NPTg29961t4++23ARQ9DeqT8lpQ+vXxMSp2en4ulwsvvvgi9u3bh5/85Cc4d+5cSe0cfRz6nFWTB0q5U5RSSCaT+NnPfoZvf/vb6OnpkU1Cl50bVhdSoOh26kwZfVL53o2N200cnnnmGZw7dw6zs7N3LDT+XUnKAyZAEcO8cOEC7HY7vF6vdH8iJruysiK0MiYp2e12ocqFQiFcvXq1ZFHuNJiij09PENHHm0gkcOXKFZw4cQKpVEqaOGSzWZmXzs5OAJCCV6FQCPF4HG1tbcK0mJ2dhcPhwMDAAM6dOyfKTVfotcYt1tbWcOnSJfj9fnR2diKfzws7hZxfBqrb29ul/Rgrg9JlZytBwyiyJfbv34+uri54vV6YTCb85Cc/wY0bNyqyGyp5aywBodfXIVTIEggbGxsYHx9HX18fLBaLdPfKZDJIp9NC0Zyfn5dEKDaBbm5uFmt/dnYWL730EhwOB2ZmZuD3+xGPx9HV1SXz1NfXh8nJyS3LJVSb65mZGQQCAYGoaPywOJfdbkcul5Oy2IRwUqmUQJtKKdy4cUMopHfLb9elGgy2sbGBK1euYHFxEcePH8fQ0BD6+/vlPnFe7HY7YrEYrl+/jo8//hjz8/N3jKuSkt9uLJUOnEQigR/+8Id47bXX8Nu//dt45513xKhYWVmRdaLj7IReCB8ahiHr6ujRoxgaGsKtW7fwl3/5l5JvUf79OzE6H0jlDhQn8Nq1a3j99dfx0ksvCRWQvS6prOmiczIJKRAC0RNi+DhwW/Fks1kcOXIEU1NTOH369I45sNWUfzabxenTp/HYY4+hp6cHfX19wgufmpqCYRhipZN1kMlkMDw8fEez4fLFVeuY9PeXfxat5VgshpGRERw+fBgNDQ2iOBOJBMbGxjA1NSUuOrNCGQeh5bFv3z40NTVhdHRUiqJVgmG2Oij1RZtOp3Hq1CmcPHkSg4ODaGgoNj4np53Y+eLiYklwlRvZ5/PJ69rb29Hd3Y2uri4EAgFEIhG89dZbFYNr1YKotLL1xDnW/E+lUoL5Wq1WzMzMwOl04sCBA7h06RLi8TgACCOiqakJHR0dYtnxnnd2dgrVLRaL4dSpUxgcHITb7ZYqomR60DplDsdOFWsul8P4+Dh6e3sRCASEn8/Dkx4ZDy7SS8ltdzqduHXrFlKpVEWK7t3KVpBjoVBAOBzG22+/jQ8//BCtra3Ys2cPuru7oVSx4io7hZFq/FlJOSzDv6PRKP7qr/4Kr776Kr75zW/i17/+NW7duiWxPEJtXD/sAcASDwDQ19eHgwcPYn5+Hj/4wQ8wOjq6bansWuWBUu7lCiyfz+PixYtoaGjAiRMnMD8/L9YYucDEQIHbp3wymYTJZEIgEIBhGJI5RysnkUiI9U5X/o033hAq13aWpi7lp6m+CDKZDD7++GNMTU0JTc7j8UgQzmQyIRaLIRaL4dq1a4LJlluT23kN1eayltezeFgsFhMlnc/nJTtxeXlZauWYzWap0cKgFQNKN27cwNzc3B1ZqTxI9LmpNib971QqhQ8//BCzs7N46qmn4Ha7EQ6HhZlgt9tLAt8sR2y1WiUzta+vD0NDQ+ju7kahUMA//MM/4OzZsxJsLVcmlaAkit4wgkYDMVTGUwhtLSwsSKyF88TyteSFs1YSe9cyaMlDl4ZMU1OTsFB0njSJBFTMO5X5+XmcOXMGx48fR0dHB4DbRclILyV8xDISPOAWFhaEcXWvzTnKpZoRo8fXmD8yNjZWQsKoJpUMjZ0qz/J1y3sQj8fxox/9CBMTE3j55Zexb98+qV3j8/lKvCHy851OpyQmTU9P48c//vK6Ak0AAAq5SURBVDFu3bp1B3W42jXUar0/UMq9kjLb2NgQjudzzz0Hk6nYIJs87Y2NDaltorNBOPkAhELHoFEulxNubzAYxKlTp0oi0pUWQK0BzEoH1PT0tJQI1UsikO2hJ2SVf+9Wj201lmpWkH5oUZEYhiGZnE1NTfB6vZLo0tvbC7/fL4yVcDiMtbU1oYCRuslDaauDcSvFXun/tbU1XL9+HaFQCF/60pdw5MgROXB46JDCR247g6/ZbFZKPNy8eROnT5/GwsJCyTXX6g1R4fH15VRaelmsPWIYxUAgqa8ul0ssYSpq4rKs5zI/Pw+Hw4GlpSU5PFgxk2OOx+Po6emBUkVeOcehVxrciUxNTSGbzeLJJ5+E0+mUYH8mk8GFCxfQ0NCA3t5edHd3i7ESCoXE6GIbu89KarkflfbJTnBovqYWJb+dEtWzjN977z1cvnwZTzzxBB5//HEcO3ZMiBM6XZf3kQyeUChU0vWtVqlp3e7oE79A0Sd2fX0d58+fRyqVwiuvvIK+vj5cvXpVeKYsIUAGAQNfTGphUJCNO3hyrq+v46OPPsLs7OxnOu5y4aLVLb27/Sz987Z7rw6/6I/r79WzgZVSUi+E/ytVmlOgZ9dVG6/+edUOrUp4Yvm1UdkkEgmcPn0a58+fh8/nw6FDh7Bnz54SSmA6nUYsFkMgEJAiWbT89Yzj8u8uH1elTU+DQLcemcxTDo0UCgX4/X4MDw8LVa69vV1onHp6PCuDkmfODGA2ykgkEnC73dLSjhTP1dVVjI2NSVVRneWyEykUCpifn8e7776LwcFBqY0fi8UQjUalUQuvnYc7H/s8pNLa3m697wSH3ure1zKWSp/H7w+Hw3jzzTfxwQcfIBAISANtemqJRAKxWAypVGpLK307qdkouatP/xyk0mSXW/A3btzAysoKvvnNb+L555/H5cuXxZJixl9LSwt6enowNTWFqakpqQVNC3/Pnj1yOHzwwQfC7wa2r/y4newEF99OtlvMd/tePq/DJtXmXlfW+iKutPm2U+b69261wcoPHr6ewe90Oi1JQXrQnMlU5N+XtyWsNobtvAkAorwJvRCS6OrqkvLJ5H0TmiEE6PV6RaHrLAm9AQkPzaamJgwMDEiAUg8UZ7NZOaQikQjm5uaES73ToGq5ZDIZXLx4UVpC8je/n9nGDBB/HnK3MEklK7zaPd3p/rwbb5lEheXlZYyMjGz7nloPpbsZ1wOj3MtFd52B25M3PT2NH/7wh3j22WfxxBNP4JFHHsHS0hIWFxcFJ2SRMZb4JGXN5/MhGo3ijTfewPDw8B0LtRYlX0nKceZy2QrLrfaaalLr6ypF+7f6/mqvLbdqq7m0tUBY5YHVWqCucrgNuA2z3Q3WzM/dbqPrY2SuhF7tc2ZmBvv375cMSf35+fl5wcoJxZBpYxiGWOqsP2+32yX45nA40NXVJcyZRCIhhwqTdm7evCksls9ScrlcSb+AL1LKPcpqst3a2+r/nSj3uzXSqn3XVgfP3Sj4WuSBUe6VsNBya5G/l5aW8NZbb+Hs2bPo7+9Hf3+/NOrQa4grpUQJzMzM4NSpUxgZGREeL1B5cisp61oYCZ/3wrkboeKphjGWwyPVFHul52tZlNW8hJ3I5zFf23kN/F8pJdm5AEp+X79+XWqf6+UxGMBnv1ngNpW0UvYiAIkZkJXC+uqskcI6S2NjYxgeHpYDDsA9W+4Pk9zLWvgi991WsM9WBlQtn1nr+x6IVWGxWPDcc89VfX4rJaKUQiQSQSqVgt1uL2n/pVt42WwWXq8XJ06cqMlyA0onz+l0wmKxoKenZ+cX+AUKS/mSnna37IDPQsrnWP+/ra1NGAT685+l3Os1K6UQDAYrKk+lVAnVVrfMeJ16s3Q99lHJkyp/P/vKltclASBrmNLY2IhAICC1Yh5UYTb4TvqA3g9hwmR5bOyzgFB2GszfSrbTRep+bPo7BqFUCsDN+z2OL0j8AKL3exBfkNSvdXfK/y/X+jBcZ69hGIFKTzwQljuAm4ZhHLvfg/giRCl1rn6tu0/q17r75GG/zgeycFhd6lKXutTl3qSu3OtSl7rUZRfKg6Lcv3e/B/AFSv1ad6fUr3X3yUN9nQ9EQLUudalLXery2cqDYrnXpS51qUtdPkO578pdKfWbSqmbSqlRpdQf3+/x3IsopbqVUh8opa4ppa4qpf5g83GvUurnSqmRzd8tm48rpdR/3rz2y0qpx+7vFexclFINSqmLSqm3Nv/fo5T69eY1/Y1SyrL5uHXz/9HN5/vu57h3Kkopj1LqdaXUDaXUdaXUk7v1viql/uXm+h1WSv1YKWXbLfdVKfXflVKLSqlh7bEd30el1Gubrx9RSr12P65lO7mvyl0p1QDgvwD4LQBDAL6tlBq6n2O6R8kD+CPDMIYAnATw+5vX88cA3jcMYz+A9zf/B4rXvX/z5/cA/MUXP+R7lj8AcF37/z8A+HPDMPYBiAP4zubj3wEQ33z8zzdf9zDJdwH8zDCMAwC+hOI177r7qpQKAvgXAI4ZhnEYQAOAf4zdc1//B4DfLHtsR/dRKeUF8KcATgB4AsCf8kB4oERP8/+ifwA8CeBd7f8/AfAn93NMn/H1vQHgH6GYoNWx+VgHirx+APivAL6tvV5e9zD8AOhCcTN8GcBbABSKSR+N5fcXwLsAntz8u3Hzdep+X0ON1+kGMFE+3t14XwEEAcwA8G7ep7cAfGU33VcAfQCG7/Y+Avg2gP+qPV7yugfl537DMlxIlNnNxx562XRPHwXwawBthmGw9c88gLbNvx/26/9PAP4VABbe8QFYNgyDNQX065Fr3Xw+sfn6h0H2AIgA+KtNCOq/KaUc2IX31TCMEID/CGAaQBjF+3Qeu/O+UnZ6Hx+K+3u/lfuuFKWUE8DfAvhDwzCS+nNG8ah/6ClKSqlXACwahnH+fo/lC5BGAI8B+AvDMB4FsILbrjuAXXVfWwB8A8UDrROAA3fCGLtWdst9BO6/cg8B0KsIdW0+9tCKUsqMomL/a8Mw/m7z4QWlVMfm8x0A2MLmYb7+pwF8XSk1CeB/oQjNfBeARynFshb69ci1bj7vBrD0RQ74HmQWwKxhGL/e/P91FJX9bryvLwOYMAwjYhjGOoC/Q/Fe78b7StnpfXwo7u/9Vu6fANi/GYm3oBi4efM+j+muRRXLxn0fwHXDMP5Me+pNAIyov4YiFs/Hf2czKn8SQEJzDx9oMQzjTwzD6DIMow/F+/YLwzD+CYAPAHxr82Xl18o5+Nbm6x8KC8kwjHkAM0qpwc2HXgJwDbvwvqIIx5xUStk31zOvddfdV012eh/fBfAbSqmWTU/nNzYfe7DkfoP+AL4K4BaAMQD/9n6P5x6v5RkUXbrLAC5t/nwVRQzyfQAjAE4B8G6+XqHIFhoDcAVFhsJ9v467uO4XALy1+fdeAGcBjAL4PwCsm4/bNv8f3Xx+7/0e9w6v8SiAc5v39v8CaNmt9xXAvwNwA8AwgB8CsO6W+wrgxyjGEtZR9Mi+czf3EcA/37zmUQC/e7+vq9JPPUO1LnWpS112odxvWKYudalLXeryOUhdudelLnWpyy6UunKvS13qUpddKHXlXpe61KUuu1Dqyr0udalLXXah1JV7XepSl7rsQqkr97rUpS512YVSV+51qUtd6rIL5f8B7cV8/rwZUpEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "no_tumor glioma_tumor glioma_tumor glioma_tumor meningioma_tumor pituitary_tumor glioma_tumor no_tumor pituitary_tumor glioma_tumor no_tumor glioma_tumor pituitary_tumor no_tumor meningioma_tumor glioma_tumor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfy0jMzhDVUt"
      },
      "source": [
        "\n",
        "def accuracy(y_pred, y):\n",
        "    top_pred= y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U2vMBGWvN8H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcfct-9Axnwq"
      },
      "source": [
        "def CNN_Model(f1, f2, f3, k1, k2, k3, l_r ):\n",
        "\n",
        "  class Net(nn.Module):\n",
        "      def __init__(self, f1, f2, f3, k1, k2, k3):\n",
        "          super(Net, self).__init__()\n",
        "          self.conv1=nn.Conv2d(in_channels=3,out_channels=f1 ,kernel_size=k1,stride=1,padding=1)\n",
        "          self.bn1=nn.BatchNorm2d(num_features=f1)\n",
        "          self.relu1=nn.ReLU()\n",
        "          self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "          self.conv2=nn.Conv2d(in_channels=f1,out_channels= f2, kernel_size=k2,stride=1,padding=1)\n",
        "          self.relu2=nn.ReLU()\n",
        "        \n",
        "          self.conv3=nn.Conv2d(in_channels=f2,out_channels=f3,kernel_size=k3,stride=1,padding=1)\n",
        "        \n",
        "          self.bn3=nn.BatchNorm2d(num_features=f3)\n",
        "          self.relu3=nn.ReLU()\n",
        "          self.drop_out = nn.Dropout()\n",
        "          v=((140-k1+ 2+1)/2 )\n",
        "          u=(v-k2+ 2+1)\n",
        "          w=(u-k3+ 2+1)\n",
        "          self.fc1=nn.Linear(in_features= int(w)*int(w)*int(f3), out_features=4)\n",
        "        \n",
        "      def forward(self,input):\n",
        "          output=self.conv1(input)\n",
        "          output=self.bn1(output)\n",
        "          output=self.relu1(output)\n",
        "            \n",
        "          output=self.pool(output)\n",
        "            \n",
        "          output=self.conv2(output)\n",
        "          output=self.relu2(output)\n",
        "            \n",
        "          output=self.conv3(output)\n",
        "          output=self.bn3(output)\n",
        "          output=self.relu3(output)\n",
        "          output=self.drop_out(output)\n",
        "          output=output.view(output.size(0), -1)\n",
        "            \n",
        "            \n",
        "          output=self.fc1(output)\n",
        "          return output\n",
        "\n",
        "  model = Net(f1, f2, f3, k1, k2, k3)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=l_r)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  if torch.cuda.is_available():\n",
        "      model = model.cuda()\n",
        "      criterion = criterion.cuda()\n",
        "    \n",
        "  print(model)\n",
        "  trainacc_values=[]\n",
        "  trainloss_values=[]\n",
        "  testacc_values=[]\n",
        "  testloss_values=[]\n",
        "  for i in range(num_epochs):\n",
        "      train_loss = 0\n",
        "      train_acc=0\n",
        "      for images, labels in train_loader:\n",
        "\n",
        "          if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "          # Training pass\n",
        "          optimizer.zero_grad()\n",
        "          output= model(images)\n",
        "          loss = criterion(output, labels)\n",
        "          acc=accuracy(output, labels)\n",
        "          #This is where the model learns by backpropagating\n",
        "          loss.backward()\n",
        "        \n",
        "          #And optimizes its weights here\n",
        "          optimizer.step()\n",
        "        \n",
        "          train_loss += loss.item()\n",
        "          train_acc += acc.item()\n",
        "     \n",
        "      trainacc_values.append(train_acc/len(train_loader))\n",
        "      trainloss_values.append(train_loss/len(train_loader))\n",
        "\n",
        "      test_loss = 0\n",
        "      test_acc=0\n",
        "      for images, labels in test_loader:\n",
        "\n",
        "          if torch.cuda.is_available():\n",
        "            images= images.cuda()\n",
        "            labels= labels.cuda()\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          output= model(images)\n",
        "        \n",
        "          loss= criterion(output, labels)\n",
        "          acc=accuracy(output, labels)\n",
        "          \n",
        "        \n",
        "          test_loss += loss.item()\n",
        "          test_acc += acc.item()\n",
        "        \n",
        "      print(\"Test loss: {} , test accuracy: {}\".format( test_loss/len(test_loader) , test_acc/len(test_loader)))\n",
        "      testacc_values.append(test_acc/len(test_loader))\n",
        "      testloss_values.append(test_loss/len(test_loader))\n",
        "  print(  max(testacc_values))\n",
        "  return max(testacc_values)      \n",
        "#CNN_Model(16, 24, 42, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIjH6iJV_dvR"
      },
      "source": [
        "\n",
        "def initialization():  \n",
        "  parameters = {}\n",
        "  f1 = choice([16, 24, 32])\n",
        "  parameters[\"f1\"] = f1\n",
        "  f2 = choice([ 40, 64, 128, 80])\n",
        "  parameters[\"f2\"] = f2\n",
        "  f3 = choice([44, 128, 64, 196])\n",
        "  parameters[\"f3\"] = f3\n",
        "  k1 = choice([17,3,7, 11])\n",
        "  parameters[\"k1\"] = k1\n",
        "  k2 = choice([17,3,7, 11])\n",
        "  parameters[\"k2\"] = k2\n",
        "  k3 = choice([17, 3,7, 11])\n",
        "  parameters[\"k3\"] = k3\n",
        "  l_r= choice([0.001, 0.01, 0.005, 0.0075])\n",
        "  parameters[\"l_r\"]= l_r\n",
        "  return parameters\n",
        "\n",
        "def generate_population(n):\n",
        "  population = []\n",
        "  for i in range(n):\n",
        "    chromosome = initialization()\n",
        "    population.append(chromosome)\n",
        "  print(population)\n",
        "  return population\n",
        "#generate_population(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL9KgDHtAgy-"
      },
      "source": [
        "# Roulette wheel selection method\n",
        "def selection(population_fitness):\n",
        "  total = sum(population_fitness)\n",
        "  percentage = [round((x/total) * 100) for x in population_fitness]\n",
        "  selection_wheel = []\n",
        "  for pop_index,num in enumerate(percentage):\n",
        "    selection_wheel.extend([pop_index]*num)\n",
        "  parent1_ind = choice(selection_wheel)\n",
        "  parent2_ind = choice(selection_wheel)\n",
        "  return [parent1_ind, parent2_ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViusckhtAhEp"
      },
      "source": [
        "def crossover(parent1, parent2):\n",
        "  child1 = {}\n",
        "  child2 = {}\n",
        "\n",
        "  child1[\"f1\"] = choice([parent1[\"f1\"], parent2[\"f1\"]])\n",
        "  child1[\"f2\"] = choice([parent1[\"f2\"], parent2[\"f2\"]])\n",
        "  child1[\"f3\"] = choice([parent1[\"f3\"], parent2[\"f3\"]])\n",
        "\n",
        "  child2[\"f1\"] = choice([parent1[\"f1\"], parent2[\"f1\"]])\n",
        "  child2[\"f2\"] = choice([parent1[\"f2\"], parent2[\"f2\"]])\n",
        "  child2[\"f3\"] = choice([parent1[\"f3\"], parent2[\"f3\"]])\n",
        "\n",
        "  child1[\"k1\"] = choice([parent1[\"k1\"], parent2[\"k1\"]])\n",
        "  child1[\"k2\"] = choice([parent1[\"k2\"], parent2[\"k2\"]])\n",
        "  child1[\"k3\"] = choice([parent1[\"k3\"], parent2[\"k3\"]])\n",
        "\n",
        "  child2[\"k1\"] = choice([parent1[\"k1\"], parent2[\"k1\"]])\n",
        "  child2[\"k2\"] = choice([parent1[\"k2\"], parent2[\"k2\"]])\n",
        "  child2[\"k3\"] = choice([parent1[\"k3\"], parent2[\"k3\"]])\n",
        "\n",
        "  child1[\"l_r\"] = parent1[\"l_r\"]\n",
        "  child2[\"l_r\"] = parent2[\"l_r\"]\n",
        "\n",
        "  return [child1, child2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6GlnjS1AhWN"
      },
      "source": [
        "def mutation(chromosome):\n",
        "  flag = randint(0,40)\n",
        "  fil=['f1', 'f2', 'f3']\n",
        "  x= random.choice(fil)\n",
        "    \n",
        "  if x==\"f1\": \n",
        "      chromosome[0] += 20\n",
        "      print(chromosome)\n",
        "  elif x==\"f2\":\n",
        "      chromosome[1] += 32\n",
        "      print(chromosome)\n",
        "\n",
        "  else:\n",
        "      chromosome[2] += 48\n",
        "      print(chromosome)\n",
        "\n",
        "  return chromosome\n",
        "#child=[32, 44, 64, 7, 0.01]\n",
        "#mutation (child)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ4mZHZjwOgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a742bdbb-0df9-4824-a82a-c21c8a61235d"
      },
      "source": [
        "generations = 10\n",
        "threshold = 90\n",
        "num_pop = 10\n",
        "\n",
        "population = generate_population(num_pop)\n",
        "\n",
        "for generation in range(generations):\n",
        "\n",
        "  population_fitness = []\n",
        "  for chromosome in population:\n",
        "    f1 = chromosome[\"f1\"]\n",
        "    f2 = chromosome[\"f2\"]\n",
        "    f3 = chromosome[\"f3\"]\n",
        "    k1 = chromosome[\"k1\"]\n",
        "    k2 = chromosome[\"k2\"]\n",
        "    k3 = chromosome[\"k3\"]\n",
        "    l_r = chromosome[\"l_r\"]\n",
        "    \n",
        "\n",
        "    try:\n",
        "      print(\"Parameters: \", chromosome)\n",
        "      acc = CNN_Model(f1, f2, f3, k1, k2, k3, l_r)\n",
        "       \n",
        "      \n",
        "      print(\"Accuracy: \", round(acc,3))\n",
        "    except:\n",
        "      acc=0\n",
        "      print(\"Parameters: \", chromosome)\n",
        "      print(\"Invalid parameters - Build fail\")\n",
        "\n",
        "    population_fitness.append(acc)\n",
        "    \n",
        "  parents_ind = selection(population_fitness)\n",
        "  parent1 = population[parents_ind[0]]\n",
        "  parent2 = population[parents_ind[1]]\n",
        "\n",
        "  children = crossover(parent1, parent2)\n",
        "  child1 = mutation(children[0])\n",
        "  child2 = mutation(children[1])\n",
        "\n",
        "  population.append(child1)\n",
        "  population.append(child2)\n",
        "\n",
        "  print(\"Generation \", generation+1,\" Outcome: \")\n",
        "  if max(population_fitness) >= threshold:\n",
        "    print(\"Obtained desired accuracy: \", max(population_fitness))\n",
        "    break\n",
        "  else:\n",
        "    print(\"Maximum accuracy in generation {} : {}\".format(generation+1, max(population_fitness)))\n",
        "\n",
        "  first_min = min(population_fitness)\n",
        "  first_min_ind = population_fitness.index(first_min)\n",
        "  population.remove(population[first_min_ind])\n",
        "  second_min = min(population_fitness)\n",
        "  second_min_ind = population_fitness.index(second_min)\n",
        "  population.remove(population[second_min_ind])\n",
        "  print(\"new population :  \",  population)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'f1': 32, 'f2': 64, 'f3': 64, 'k1': 11, 'k2': 11, 'k3': 11, 'l_r': 0.01}, {'f1': 16, 'f2': 128, 'f3': 44, 'k1': 7, 'k2': 17, 'k3': 7, 'l_r': 0.005}, {'f1': 24, 'f2': 64, 'f3': 44, 'k1': 11, 'k2': 3, 'k3': 11, 'l_r': 0.001}, {'f1': 24, 'f2': 80, 'f3': 44, 'k1': 7, 'k2': 11, 'k3': 7, 'l_r': 0.001}, {'f1': 24, 'f2': 80, 'f3': 44, 'k1': 3, 'k2': 7, 'k3': 11, 'l_r': 0.005}, {'f1': 32, 'f2': 80, 'f3': 44, 'k1': 17, 'k2': 17, 'k3': 7, 'l_r': 0.0075}, {'f1': 32, 'f2': 80, 'f3': 128, 'k1': 7, 'k2': 3, 'k3': 11, 'l_r': 0.01}, {'f1': 16, 'f2': 64, 'f3': 128, 'k1': 17, 'k2': 17, 'k3': 11, 'l_r': 0.01}, {'f1': 16, 'f2': 64, 'f3': 44, 'k1': 7, 'k2': 7, 'k3': 7, 'l_r': 0.01}, {'f1': 32, 'f2': 64, 'f3': 44, 'k1': 7, 'k2': 17, 'k3': 11, 'l_r': 0.01}]\n",
            "Parameters:  {'f1': 32, 'f2': 64, 'f3': 64, 'k1': 11, 'k2': 11, 'k3': 11, 'l_r': 0.01}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=160000, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 158.05555534362793 , test accuracy: 0.3854166716337204\n",
            "Test loss: 132.8206386566162 , test accuracy: 0.2916666679084301\n",
            "Test loss: 99.88760566711426 , test accuracy: 0.3697916716337204\n",
            "Test loss: 104.32386875152588 , test accuracy: 0.3229166716337204\n",
            "Test loss: 118.38968467712402 , test accuracy: 0.2864583358168602\n",
            "Test loss: 101.15474033355713 , test accuracy: 0.328125\n",
            "Test loss: 72.98864555358887 , test accuracy: 0.2447916679084301\n",
            "Test loss: 74.32332801818848 , test accuracy: 0.3229166716337204\n",
            "Test loss: 72.55530834197998 , test accuracy: 0.3072916716337204\n",
            "Test loss: 62.958027839660645 , test accuracy: 0.28125\n",
            "Test loss: 62.942575454711914 , test accuracy: 0.34895833395421505\n",
            "Test loss: 56.164018630981445 , test accuracy: 0.3020833358168602\n",
            "Test loss: 54.113609313964844 , test accuracy: 0.3645833358168602\n",
            "Test loss: 55.36735534667969 , test accuracy: 0.296875\n",
            "Test loss: 44.59331750869751 , test accuracy: 0.31770833395421505\n",
            "Test loss: 48.346744537353516 , test accuracy: 0.3177083358168602\n",
            "Test loss: 32.53737115859985 , test accuracy: 0.3229166679084301\n",
            "Test loss: 39.85986280441284 , test accuracy: 0.38020833395421505\n",
            "Test loss: 32.16624069213867 , test accuracy: 0.328125\n",
            "Test loss: 30.392812728881836 , test accuracy: 0.3541666716337204\n",
            "Test loss: 36.11857891082764 , test accuracy: 0.359375\n",
            "Test loss: 36.234254360198975 , test accuracy: 0.3072916679084301\n",
            "Test loss: 31.561121940612793 , test accuracy: 0.3177083358168602\n",
            "Test loss: 35.77992820739746 , test accuracy: 0.3541666716337204\n",
            "Test loss: 34.80112075805664 , test accuracy: 0.3020833358168602\n",
            "Test loss: 30.064876079559326 , test accuracy: 0.3645833358168602\n",
            "Test loss: 39.705573081970215 , test accuracy: 0.3072916679084301\n",
            "Test loss: 37.240227699279785 , test accuracy: 0.2760416679084301\n",
            "Test loss: 26.56694483757019 , test accuracy: 0.3958333358168602\n",
            "Test loss: 29.41190242767334 , test accuracy: 0.3645833358168602\n",
            "Test loss: 30.902788639068604 , test accuracy: 0.3854166716337204\n",
            "Test loss: 26.404605388641357 , test accuracy: 0.3333333358168602\n",
            "Test loss: 30.237359523773193 , test accuracy: 0.3541666716337204\n",
            "Test loss: 36.920870780944824 , test accuracy: 0.296875\n",
            "Test loss: 26.573174953460693 , test accuracy: 0.3802083358168602\n",
            "Test loss: 26.262033462524414 , test accuracy: 0.4375\n",
            "Test loss: 29.177616596221924 , test accuracy: 0.3385416716337204\n",
            "Test loss: 24.315743446350098 , test accuracy: 0.328125\n",
            "Test loss: 24.463295459747314 , test accuracy: 0.3385416679084301\n",
            "Test loss: 27.804444313049316 , test accuracy: 0.359375\n",
            "Test loss: 25.10744047164917 , test accuracy: 0.3333333358168602\n",
            "Test loss: 29.75230836868286 , test accuracy: 0.3072916679084301\n",
            "Test loss: 24.84452772140503 , test accuracy: 0.25\n",
            "Test loss: 22.039682865142822 , test accuracy: 0.2864583432674408\n",
            "Test loss: 19.41011953353882 , test accuracy: 0.3854166679084301\n",
            "Test loss: 21.98053741455078 , test accuracy: 0.296875\n",
            "Test loss: 23.332196712493896 , test accuracy: 0.2916666679084301\n",
            "Test loss: 25.83330202102661 , test accuracy: 0.4010416716337204\n",
            "Test loss: 24.060739755630493 , test accuracy: 0.4375\n",
            "Test loss: 22.64333415031433 , test accuracy: 0.3333333358168602\n",
            "0.4375\n",
            "Accuracy:  0.438\n",
            "Parameters:  {'f1': 16, 'f2': 128, 'f3': 44, 'k1': 7, 'k2': 17, 'k3': 7, 'l_r': 0.005}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 128, kernel_size=(17, 17), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(128, 44, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=110000, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 94.62464714050293 , test accuracy: 0.296875\n",
            "Test loss: 87.77865505218506 , test accuracy: 0.2395833358168602\n",
            "Test loss: 58.299062728881836 , test accuracy: 0.2552083358168602\n",
            "Test loss: 65.00808811187744 , test accuracy: 0.21875\n",
            "Test loss: 63.30817222595215 , test accuracy: 0.28125\n",
            "Test loss: 61.67387104034424 , test accuracy: 0.3072916716337204\n",
            "Test loss: 69.77731704711914 , test accuracy: 0.2604166716337204\n",
            "Test loss: 67.35563659667969 , test accuracy: 0.3072916716337204\n",
            "Test loss: 51.51270031929016 , test accuracy: 0.3020833432674408\n",
            "Test loss: 54.410491943359375 , test accuracy: 0.28645833395421505\n",
            "Test loss: 46.86740303039551 , test accuracy: 0.3645833358168602\n",
            "Test loss: 45.91913843154907 , test accuracy: 0.28125\n",
            "Test loss: 47.00605583190918 , test accuracy: 0.2760416679084301\n",
            "Test loss: 47.060965061187744 , test accuracy: 0.28125\n",
            "Test loss: 35.248756408691406 , test accuracy: 0.25\n",
            "Test loss: 39.21501302719116 , test accuracy: 0.265625\n",
            "Test loss: 39.787864685058594 , test accuracy: 0.28125\n",
            "Test loss: 30.33973455429077 , test accuracy: 0.3020833358168602\n",
            "Test loss: 38.297964572906494 , test accuracy: 0.25\n",
            "Test loss: 34.61587333679199 , test accuracy: 0.28125\n",
            "Test loss: 43.71843385696411 , test accuracy: 0.203125\n",
            "Test loss: 35.74488592147827 , test accuracy: 0.22395833395421505\n",
            "Test loss: 36.18639922142029 , test accuracy: 0.28125\n",
            "Test loss: 33.72949552536011 , test accuracy: 0.1875\n",
            "Test loss: 28.504730701446533 , test accuracy: 0.296875\n",
            "Test loss: 30.019465446472168 , test accuracy: 0.2552083358168602\n",
            "Test loss: 28.576953649520874 , test accuracy: 0.2864583358168602\n",
            "Test loss: 28.366275310516357 , test accuracy: 0.2604166716337204\n",
            "Test loss: 30.976204872131348 , test accuracy: 0.265625\n",
            "Test loss: 28.364580392837524 , test accuracy: 0.328125\n",
            "Test loss: 28.794989824295044 , test accuracy: 0.3072916716337204\n",
            "Test loss: 27.157204151153564 , test accuracy: 0.2760416716337204\n",
            "Test loss: 25.51398229598999 , test accuracy: 0.28645833395421505\n",
            "Test loss: 21.944369077682495 , test accuracy: 0.2447916679084301\n",
            "Test loss: 28.622862577438354 , test accuracy: 0.2708333358168602\n",
            "Test loss: 29.33142590522766 , test accuracy: 0.3020833358168602\n",
            "Test loss: 31.000916957855225 , test accuracy: 0.28125\n",
            "Test loss: 28.719883918762207 , test accuracy: 0.3020833358168602\n",
            "Test loss: 25.43259048461914 , test accuracy: 0.328125\n",
            "Test loss: 27.76715660095215 , test accuracy: 0.28125\n",
            "Test loss: 21.429970502853394 , test accuracy: 0.3333333358168602\n",
            "Test loss: 24.1168212890625 , test accuracy: 0.3802083358168602\n",
            "Test loss: 24.39847421646118 , test accuracy: 0.2552083358168602\n",
            "Test loss: 24.515259265899658 , test accuracy: 0.2760416679084301\n",
            "Test loss: 23.419156551361084 , test accuracy: 0.2916666679084301\n",
            "Test loss: 22.1282901763916 , test accuracy: 0.3645833358168602\n",
            "Test loss: 20.78169345855713 , test accuracy: 0.3229166716337204\n",
            "Test loss: 21.694388508796692 , test accuracy: 0.3854166716337204\n",
            "Test loss: 21.046236038208008 , test accuracy: 0.34375\n",
            "Test loss: 21.219063758850098 , test accuracy: 0.3229166679084301\n",
            "0.3854166716337204\n",
            "Accuracy:  0.385\n",
            "Parameters:  {'f1': 24, 'f2': 64, 'f3': 44, 'k1': 11, 'k2': 3, 'k3': 11, 'l_r': 0.001}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 24, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(64, 44, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=148016, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 29.80021095275879 , test accuracy: 0.2135416679084301\n",
            "Test loss: 30.673823356628418 , test accuracy: 0.3385416716337204\n",
            "Test loss: 42.302080154418945 , test accuracy: 0.3072916716337204\n",
            "Test loss: 31.311022758483887 , test accuracy: 0.3697916716337204\n",
            "Test loss: 48.53548049926758 , test accuracy: 0.2760416679084301\n",
            "Test loss: 34.486088514328 , test accuracy: 0.3177083432674408\n",
            "Test loss: 42.652289390563965 , test accuracy: 0.2552083358168602\n",
            "Test loss: 41.70002841949463 , test accuracy: 0.3125\n",
            "Test loss: 44.54346752166748 , test accuracy: 0.3020833358168602\n",
            "Test loss: 51.92495918273926 , test accuracy: 0.3072916716337204\n",
            "Test loss: 57.08123779296875 , test accuracy: 0.296875\n",
            "Test loss: 50.18598175048828 , test accuracy: 0.3541666716337204\n",
            "Test loss: 36.84671211242676 , test accuracy: 0.25520833395421505\n",
            "Test loss: 36.32949352264404 , test accuracy: 0.3229166716337204\n",
            "Test loss: 49.02726221084595 , test accuracy: 0.34375\n",
            "Test loss: 56.84101390838623 , test accuracy: 0.3020833358168602\n",
            "Test loss: 46.20930051803589 , test accuracy: 0.328125\n",
            "Test loss: 45.699514865875244 , test accuracy: 0.3020833432674408\n",
            "Test loss: 48.06856727600098 , test accuracy: 0.375\n",
            "Test loss: 48.20885944366455 , test accuracy: 0.2916666679084301\n",
            "Test loss: 60.56914234161377 , test accuracy: 0.3020833358168602\n",
            "Test loss: 67.36609220504761 , test accuracy: 0.3385416716337204\n",
            "Test loss: 60.932196617126465 , test accuracy: 0.3645833358168602\n",
            "Test loss: 60.54739475250244 , test accuracy: 0.3177083358168602\n",
            "Test loss: 57.307047843933105 , test accuracy: 0.3489583358168602\n",
            "Test loss: 52.07557916641235 , test accuracy: 0.3697916716337204\n",
            "Test loss: 56.18439769744873 , test accuracy: 0.390625\n",
            "Test loss: 46.05550765991211 , test accuracy: 0.390625\n",
            "Test loss: 48.2309513092041 , test accuracy: 0.2708333358168602\n",
            "Test loss: 68.11912250518799 , test accuracy: 0.3541666716337204\n",
            "Test loss: 57.34756565093994 , test accuracy: 0.33333333395421505\n",
            "Test loss: 64.35976696014404 , test accuracy: 0.34375\n",
            "Test loss: 54.64594841003418 , test accuracy: 0.3489583358168602\n",
            "Test loss: 59.22122383117676 , test accuracy: 0.3072916716337204\n",
            "Test loss: 67.21137619018555 , test accuracy: 0.3854166716337204\n",
            "Test loss: 62.226866722106934 , test accuracy: 0.4427083432674408\n",
            "Test loss: 66.04554653167725 , test accuracy: 0.3958333432674408\n",
            "Test loss: 54.32368469238281 , test accuracy: 0.359375\n",
            "Test loss: 61.90181922912598 , test accuracy: 0.40625\n",
            "Test loss: 54.233009338378906 , test accuracy: 0.4010416716337204\n",
            "Test loss: 54.07953071594238 , test accuracy: 0.3385416716337204\n",
            "Test loss: 63.04726314544678 , test accuracy: 0.34375\n",
            "Test loss: 56.72155952453613 , test accuracy: 0.3333333358168602\n",
            "Test loss: 65.75416660308838 , test accuracy: 0.3385416716337204\n",
            "Test loss: 64.57652187347412 , test accuracy: 0.3177083358168602\n",
            "Test loss: 51.6607780456543 , test accuracy: 0.3125\n",
            "Test loss: 68.83936500549316 , test accuracy: 0.3645833358168602\n",
            "Test loss: 67.04014492034912 , test accuracy: 0.359375\n",
            "Test loss: 59.49987983703613 , test accuracy: 0.3645833358168602\n",
            "Test loss: 58.31947135925293 , test accuracy: 0.375\n",
            "0.4427083432674408\n",
            "Accuracy:  0.443\n",
            "Parameters:  {'f1': 24, 'f2': 80, 'f3': 44, 'k1': 7, 'k2': 11, 'k3': 7, 'l_r': 0.001}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 24, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(24, 80, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(80, 44, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=137984, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 28.573834896087646 , test accuracy: 0.2708333358168602\n",
            "Test loss: 15.272085666656494 , test accuracy: 0.265625\n",
            "Test loss: 36.29220008850098 , test accuracy: 0.203125\n",
            "Test loss: 28.425076484680176 , test accuracy: 0.31770833395421505\n",
            "Test loss: 37.76633262634277 , test accuracy: 0.3072916679084301\n",
            "Test loss: 34.663066387176514 , test accuracy: 0.2447916679084301\n",
            "Test loss: 36.41998624801636 , test accuracy: 0.2916666679084301\n",
            "Test loss: 35.86894488334656 , test accuracy: 0.296875\n",
            "Test loss: 36.6531195640564 , test accuracy: 0.328125\n",
            "Test loss: 37.61802816390991 , test accuracy: 0.3125\n",
            "Test loss: 35.959078311920166 , test accuracy: 0.2760416679084301\n",
            "Test loss: 44.738253116607666 , test accuracy: 0.2760416716337204\n",
            "Test loss: 41.03762245178223 , test accuracy: 0.2708333358168602\n",
            "Test loss: 48.8446102142334 , test accuracy: 0.21875\n",
            "Test loss: 47.82397937774658 , test accuracy: 0.2239583358168602\n",
            "Test loss: 51.042070388793945 , test accuracy: 0.3229166716337204\n",
            "Test loss: 51.99525833129883 , test accuracy: 0.2447916716337204\n",
            "Test loss: 45.15571880340576 , test accuracy: 0.25\n",
            "Test loss: 44.608896255493164 , test accuracy: 0.265625\n",
            "Test loss: 49.73395347595215 , test accuracy: 0.2708333358168602\n",
            "Test loss: 47.92292785644531 , test accuracy: 0.2916666716337204\n",
            "Test loss: 39.960357666015625 , test accuracy: 0.3020833358168602\n",
            "Test loss: 42.8732271194458 , test accuracy: 0.3177083358168602\n",
            "Test loss: 48.468010902404785 , test accuracy: 0.234375\n",
            "Test loss: 57.77325487136841 , test accuracy: 0.28125\n",
            "Test loss: 55.75284385681152 , test accuracy: 0.265625\n",
            "Test loss: 53.492183685302734 , test accuracy: 0.2916666679084301\n",
            "Test loss: 56.509249687194824 , test accuracy: 0.2604166679084301\n",
            "Test loss: 59.87769031524658 , test accuracy: 0.2916666716337204\n",
            "Test loss: 52.43349361419678 , test accuracy: 0.2760416679084301\n",
            "Test loss: 68.13955688476562 , test accuracy: 0.2447916679084301\n",
            "Test loss: 58.051180839538574 , test accuracy: 0.28125\n",
            "Test loss: 51.46501350402832 , test accuracy: 0.2760416679084301\n",
            "Test loss: 53.057745933532715 , test accuracy: 0.28125\n",
            "Test loss: 60.5966739654541 , test accuracy: 0.296875\n",
            "Test loss: 71.95636558532715 , test accuracy: 0.3072916716337204\n",
            "Test loss: 59.38046360015869 , test accuracy: 0.3072916679084301\n",
            "Test loss: 67.82418823242188 , test accuracy: 0.3333333358168602\n",
            "Test loss: 64.15423583984375 , test accuracy: 0.3385416716337204\n",
            "Test loss: 59.50753974914551 , test accuracy: 0.31770833395421505\n",
            "Test loss: 56.002737522125244 , test accuracy: 0.3020833358168602\n",
            "Test loss: 61.93256759643555 , test accuracy: 0.3125\n",
            "Test loss: 69.4597635269165 , test accuracy: 0.3385416716337204\n",
            "Test loss: 59.31204795837402 , test accuracy: 0.3385416679084301\n",
            "Test loss: 51.32839393615723 , test accuracy: 0.3125\n",
            "Test loss: 63.609039306640625 , test accuracy: 0.2916666716337204\n",
            "Test loss: 56.63049793243408 , test accuracy: 0.2760416679084301\n",
            "Test loss: 62.34524440765381 , test accuracy: 0.28645833395421505\n",
            "Test loss: 60.148035526275635 , test accuracy: 0.296875\n",
            "Test loss: 83.48637008666992 , test accuracy: 0.3072916716337204\n",
            "0.3385416716337204\n",
            "Accuracy:  0.339\n",
            "Parameters:  {'f1': 24, 'f2': 80, 'f3': 44, 'k1': 3, 'k2': 7, 'k3': 11, 'l_r': 0.005}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(24, 80, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(80, 44, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=148016, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 67.64327096939087 , test accuracy: 0.2552083358168602\n",
            "Test loss: 122.21214866638184 , test accuracy: 0.3177083358168602\n",
            "Test loss: 154.82188034057617 , test accuracy: 0.2708333358168602\n",
            "Test loss: 178.7471103668213 , test accuracy: 0.3229166716337204\n",
            "Test loss: 166.6364459991455 , test accuracy: 0.2239583358168602\n",
            "Test loss: 183.26516342163086 , test accuracy: 0.3072916716337204\n",
            "Test loss: 175.59689903259277 , test accuracy: 0.2760416679084301\n",
            "Test loss: 175.89757537841797 , test accuracy: 0.234375\n",
            "Test loss: 169.83389854431152 , test accuracy: 0.23958333395421505\n",
            "Test loss: 151.99491691589355 , test accuracy: 0.2708333358168602\n",
            "Test loss: 168.14959716796875 , test accuracy: 0.2708333358168602\n",
            "Test loss: 184.73373222351074 , test accuracy: 0.2760416679084301\n",
            "Test loss: 163.3598175048828 , test accuracy: 0.28125\n",
            "Test loss: 183.11928176879883 , test accuracy: 0.2604166679084301\n",
            "Test loss: 163.70743560791016 , test accuracy: 0.2239583358168602\n",
            "Test loss: 163.70965385437012 , test accuracy: 0.28125\n",
            "Test loss: 171.12034606933594 , test accuracy: 0.328125\n",
            "Test loss: 145.5751438140869 , test accuracy: 0.2760416679084301\n",
            "Test loss: 144.14243698120117 , test accuracy: 0.3125\n",
            "Test loss: 195.96660614013672 , test accuracy: 0.3333333358168602\n",
            "Test loss: 174.49572086334229 , test accuracy: 0.3385416716337204\n",
            "Test loss: 142.84329509735107 , test accuracy: 0.3020833358168602\n",
            "Test loss: 133.12879371643066 , test accuracy: 0.2760416679084301\n",
            "Test loss: 135.9152717590332 , test accuracy: 0.31770833395421505\n",
            "Test loss: 137.52921295166016 , test accuracy: 0.34375\n",
            "Test loss: 128.6350269317627 , test accuracy: 0.34375\n",
            "Test loss: 110.14659309387207 , test accuracy: 0.3541666716337204\n",
            "Test loss: 135.36948204040527 , test accuracy: 0.34375\n",
            "Test loss: 122.87356185913086 , test accuracy: 0.2916666716337204\n",
            "Test loss: 125.76501274108887 , test accuracy: 0.3854166716337204\n",
            "Test loss: 126.90658569335938 , test accuracy: 0.359375\n",
            "Test loss: 107.83118629455566 , test accuracy: 0.3333333358168602\n",
            "Test loss: 114.2676773071289 , test accuracy: 0.328125\n",
            "Test loss: 117.33040237426758 , test accuracy: 0.328125\n",
            "Test loss: 136.4314260482788 , test accuracy: 0.328125\n",
            "Test loss: 118.64669418334961 , test accuracy: 0.3541666679084301\n",
            "Test loss: 101.52717208862305 , test accuracy: 0.3125\n",
            "Test loss: 117.6411542892456 , test accuracy: 0.296875\n",
            "Test loss: 106.88073539733887 , test accuracy: 0.3125\n",
            "Test loss: 122.12095069885254 , test accuracy: 0.2760416679084301\n",
            "Test loss: 108.91927337646484 , test accuracy: 0.3541666716337204\n",
            "Test loss: 110.56435871124268 , test accuracy: 0.2604166716337204\n",
            "Test loss: 108.74960899353027 , test accuracy: 0.3125\n",
            "Test loss: 122.64814758300781 , test accuracy: 0.3697916716337204\n",
            "Test loss: 108.38021945953369 , test accuracy: 0.3229166716337204\n",
            "Test loss: 101.73760986328125 , test accuracy: 0.3333333358168602\n",
            "Test loss: 99.76153755187988 , test accuracy: 0.375\n",
            "Test loss: 108.69256591796875 , test accuracy: 0.390625\n",
            "Test loss: 113.9810562133789 , test accuracy: 0.3229166716337204\n",
            "Test loss: 107.15702819824219 , test accuracy: 0.3072916679084301\n",
            "0.390625\n",
            "Accuracy:  0.391\n",
            "Parameters:  {'f1': 32, 'f2': 80, 'f3': 44, 'k1': 17, 'k2': 17, 'k3': 7, 'l_r': 0.0075}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(17, 17), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 80, kernel_size=(17, 17), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(80, 44, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=89100, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 117.74826908111572 , test accuracy: 0.2447916679084301\n",
            "Test loss: 90.61242294311523 , test accuracy: 0.2135416679084301\n",
            "Test loss: 113.9620590209961 , test accuracy: 0.234375\n",
            "Test loss: 98.74256324768066 , test accuracy: 0.296875\n",
            "Test loss: 71.14844799041748 , test accuracy: 0.3020833358168602\n",
            "Test loss: 43.46129894256592 , test accuracy: 0.2291666679084301\n",
            "Test loss: 65.79702758789062 , test accuracy: 0.2291666679084301\n",
            "Test loss: 48.22088003158569 , test accuracy: 0.2291666716337204\n",
            "Test loss: 38.23424673080444 , test accuracy: 0.2291666679084301\n",
            "Test loss: 55.51768207550049 , test accuracy: 0.234375\n",
            "Test loss: 57.13770532608032 , test accuracy: 0.2083333358168602\n",
            "Test loss: 39.68270778656006 , test accuracy: 0.19270833395421505\n",
            "Test loss: 40.295974135398865 , test accuracy: 0.28125\n",
            "Test loss: 42.71981620788574 , test accuracy: 0.3177083358168602\n",
            "Test loss: 36.15828800201416 , test accuracy: 0.25\n",
            "Test loss: 42.842413902282715 , test accuracy: 0.2447916679084301\n",
            "Test loss: 29.359015464782715 , test accuracy: 0.28125\n",
            "Test loss: 30.583821296691895 , test accuracy: 0.3333333358168602\n",
            "Test loss: 32.578574657440186 , test accuracy: 0.25\n",
            "Test loss: 32.5674569606781 , test accuracy: 0.2864583358168602\n",
            "Test loss: 24.416255354881287 , test accuracy: 0.2708333358168602\n",
            "Test loss: 37.42581796646118 , test accuracy: 0.375\n",
            "Test loss: 33.18129825592041 , test accuracy: 0.28645833395421505\n",
            "Test loss: 35.28187608718872 , test accuracy: 0.2864583358168602\n",
            "Test loss: 30.470576763153076 , test accuracy: 0.3125\n",
            "Test loss: 31.02898073196411 , test accuracy: 0.2916666716337204\n",
            "Test loss: 34.37658929824829 , test accuracy: 0.3229166679084301\n",
            "Test loss: 24.153802633285522 , test accuracy: 0.28125\n",
            "Test loss: 28.06478524208069 , test accuracy: 0.34375\n",
            "Test loss: 23.183836817741394 , test accuracy: 0.3177083358168602\n",
            "Test loss: 32.20881748199463 , test accuracy: 0.2864583358168602\n",
            "Test loss: 26.600919246673584 , test accuracy: 0.3229166716337204\n",
            "Test loss: 31.27935028076172 , test accuracy: 0.3385416679084301\n",
            "Test loss: 29.87507390975952 , test accuracy: 0.3229166716337204\n",
            "Test loss: 22.076987266540527 , test accuracy: 0.3229166716337204\n",
            "Test loss: 33.335886001586914 , test accuracy: 0.3177083358168602\n",
            "Test loss: 25.8801531791687 , test accuracy: 0.3020833358168602\n",
            "Test loss: 20.69196081161499 , test accuracy: 0.328125\n",
            "Test loss: 17.24463129043579 , test accuracy: 0.3229166679084301\n",
            "Test loss: 21.87990975379944 , test accuracy: 0.3541666716337204\n",
            "Test loss: 17.853246808052063 , test accuracy: 0.3541666716337204\n",
            "Test loss: 19.03135120868683 , test accuracy: 0.3020833358168602\n",
            "Test loss: 14.021500587463379 , test accuracy: 0.3333333358168602\n",
            "Test loss: 18.186851382255554 , test accuracy: 0.3125\n",
            "Test loss: 19.550397753715515 , test accuracy: 0.3854166716337204\n",
            "Test loss: 19.351847171783447 , test accuracy: 0.359375\n",
            "Test loss: 20.373315811157227 , test accuracy: 0.3854166716337204\n",
            "Test loss: 17.531419277191162 , test accuracy: 0.390625\n",
            "Test loss: 20.349058866500854 , test accuracy: 0.4270833358168602\n",
            "Test loss: 18.544377326965332 , test accuracy: 0.375\n",
            "0.4270833358168602\n",
            "Accuracy:  0.427\n",
            "Parameters:  {'f1': 32, 'f2': 80, 'f3': 128, 'k1': 7, 'k2': 3, 'k3': 11, 'l_r': 0.01}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(80, 128, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=460800, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 504.5596809387207 , test accuracy: 0.15625\n",
            "Test loss: 608.6918487548828 , test accuracy: 0.2135416679084301\n",
            "Test loss: 609.4253234863281 , test accuracy: 0.2447916679084301\n",
            "Test loss: 583.1441497802734 , test accuracy: 0.27083333395421505\n",
            "Test loss: 484.57242584228516 , test accuracy: 0.28125\n",
            "Test loss: 494.3283462524414 , test accuracy: 0.2864583358168602\n",
            "Test loss: 457.8426284790039 , test accuracy: 0.234375\n",
            "Test loss: 436.0977096557617 , test accuracy: 0.2395833358168602\n",
            "Test loss: 514.6009368896484 , test accuracy: 0.3020833358168602\n",
            "Test loss: 437.33909606933594 , test accuracy: 0.2708333358168602\n",
            "Test loss: 425.46461486816406 , test accuracy: 0.3385416716337204\n",
            "Test loss: 402.219051361084 , test accuracy: 0.3125\n",
            "Test loss: 345.77778244018555 , test accuracy: 0.265625\n",
            "Test loss: 331.1120796203613 , test accuracy: 0.2916666679084301\n",
            "Test loss: 342.2385368347168 , test accuracy: 0.3541666716337204\n",
            "Test loss: 396.556583404541 , test accuracy: 0.3072916679084301\n",
            "Test loss: 290.3504104614258 , test accuracy: 0.2552083358168602\n",
            "Test loss: 270.6757278442383 , test accuracy: 0.28125\n",
            "Test loss: 262.21452713012695 , test accuracy: 0.3229166716337204\n",
            "Test loss: 279.4478073120117 , test accuracy: 0.2916666716337204\n",
            "Test loss: 265.4056587219238 , test accuracy: 0.375\n",
            "Test loss: 244.05384635925293 , test accuracy: 0.3541666679084301\n",
            "Test loss: 210.18892860412598 , test accuracy: 0.3020833358168602\n",
            "Test loss: 178.13653373718262 , test accuracy: 0.28645833395421505\n",
            "Test loss: 165.59984397888184 , test accuracy: 0.3385416716337204\n",
            "Test loss: 195.48381996154785 , test accuracy: 0.296875\n",
            "Test loss: 169.86217880249023 , test accuracy: 0.3177083358168602\n",
            "Test loss: 199.79013061523438 , test accuracy: 0.3072916679084301\n",
            "Test loss: 190.19360256195068 , test accuracy: 0.3802083358168602\n",
            "Test loss: 164.06118774414062 , test accuracy: 0.2864583358168602\n",
            "Test loss: 151.10428428649902 , test accuracy: 0.296875\n",
            "Test loss: 167.35186767578125 , test accuracy: 0.3072916679084301\n",
            "Test loss: 164.81161499023438 , test accuracy: 0.3177083358168602\n",
            "Test loss: 175.7092742919922 , test accuracy: 0.3020833358168602\n",
            "Test loss: 178.68354415893555 , test accuracy: 0.296875\n",
            "Test loss: 156.52948760986328 , test accuracy: 0.2864583358168602\n",
            "Test loss: 154.7954444885254 , test accuracy: 0.265625\n",
            "Test loss: 128.59021949768066 , test accuracy: 0.3385416716337204\n",
            "Test loss: 136.0028953552246 , test accuracy: 0.25\n",
            "Test loss: 142.39451026916504 , test accuracy: 0.25\n",
            "Test loss: 153.03540420532227 , test accuracy: 0.2916666679084301\n",
            "Test loss: 154.06361198425293 , test accuracy: 0.2916666679084301\n",
            "Test loss: 151.33132362365723 , test accuracy: 0.3177083358168602\n",
            "Test loss: 159.9899673461914 , test accuracy: 0.3385416716337204\n",
            "Test loss: 138.45268058776855 , test accuracy: 0.328125\n",
            "Test loss: 130.42571640014648 , test accuracy: 0.3385416716337204\n",
            "Test loss: 142.9966983795166 , test accuracy: 0.375\n",
            "Test loss: 193.94461059570312 , test accuracy: 0.265625\n",
            "Test loss: 174.4596824645996 , test accuracy: 0.2291666679084301\n",
            "Test loss: 184.46795272827148 , test accuracy: 0.234375\n",
            "0.3802083358168602\n",
            "Accuracy:  0.38\n",
            "Parameters:  {'f1': 16, 'f2': 64, 'f3': 128, 'k1': 17, 'k2': 17, 'k3': 11, 'l_r': 0.01}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(17, 17), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 64, kernel_size=(17, 17), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=215168, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 126.28552341461182 , test accuracy: 0.3489583432674408\n",
            "Test loss: 171.49636268615723 , test accuracy: 0.328125\n",
            "Test loss: 226.39686393737793 , test accuracy: 0.265625\n",
            "Test loss: 234.1112518310547 , test accuracy: 0.2447916679084301\n",
            "Test loss: 171.17643928527832 , test accuracy: 0.25\n",
            "Test loss: 171.60193634033203 , test accuracy: 0.25\n",
            "Test loss: 191.65570449829102 , test accuracy: 0.1510416679084301\n",
            "Test loss: 134.67075729370117 , test accuracy: 0.2708333358168602\n",
            "Test loss: 95.76524353027344 , test accuracy: 0.390625\n",
            "Test loss: 96.15849876403809 , test accuracy: 0.3802083358168602\n",
            "Test loss: 58.659485816955566 , test accuracy: 0.28125\n",
            "Test loss: 60.28529167175293 , test accuracy: 0.296875\n",
            "Test loss: 62.62552618980408 , test accuracy: 0.3333333358168602\n",
            "Test loss: 54.384389877319336 , test accuracy: 0.328125\n",
            "Test loss: 57.930012702941895 , test accuracy: 0.2760416679084301\n",
            "Test loss: 54.04439306259155 , test accuracy: 0.3229166716337204\n",
            "Test loss: 49.966060638427734 , test accuracy: 0.21875\n",
            "Test loss: 49.8314790725708 , test accuracy: 0.3020833358168602\n",
            "Test loss: 49.97353529930115 , test accuracy: 0.3333333358168602\n",
            "Test loss: 54.81534004211426 , test accuracy: 0.3072916716337204\n",
            "Test loss: 38.814634799957275 , test accuracy: 0.20833333395421505\n",
            "Test loss: 49.33392143249512 , test accuracy: 0.2447916679084301\n",
            "Test loss: 46.34363079071045 , test accuracy: 0.3020833358168602\n",
            "Test loss: 47.148311614990234 , test accuracy: 0.2708333358168602\n",
            "Test loss: 39.401018142700195 , test accuracy: 0.375\n",
            "Test loss: 39.9679012298584 , test accuracy: 0.3125\n",
            "Test loss: 46.59883689880371 , test accuracy: 0.2708333358168602\n",
            "Test loss: 28.966582775115967 , test accuracy: 0.2864583358168602\n",
            "Test loss: 33.73848581314087 , test accuracy: 0.40625\n",
            "Test loss: 41.528425216674805 , test accuracy: 0.3125\n",
            "Test loss: 34.43953800201416 , test accuracy: 0.3072916679084301\n",
            "Test loss: 35.381343364715576 , test accuracy: 0.2916666679084301\n",
            "Test loss: 46.10659694671631 , test accuracy: 0.28125\n",
            "Test loss: 27.63428282737732 , test accuracy: 0.4010416716337204\n",
            "Test loss: 34.93011283874512 , test accuracy: 0.3125\n",
            "Test loss: 28.92637348175049 , test accuracy: 0.3020833358168602\n",
            "Test loss: 29.978703260421753 , test accuracy: 0.34375\n",
            "Test loss: 29.787960052490234 , test accuracy: 0.3958333432674408\n",
            "Test loss: 36.17789816856384 , test accuracy: 0.2916666679084301\n",
            "Test loss: 24.847575664520264 , test accuracy: 0.3489583358168602\n",
            "Test loss: 25.479585647583008 , test accuracy: 0.3385416716337204\n",
            "Test loss: 33.58027791976929 , test accuracy: 0.328125\n",
            "Test loss: 21.56724190711975 , test accuracy: 0.28645833395421505\n",
            "Test loss: 25.432374954223633 , test accuracy: 0.3489583432674408\n",
            "Test loss: 26.04478430747986 , test accuracy: 0.3177083358168602\n",
            "Test loss: 24.802618503570557 , test accuracy: 0.328125\n",
            "Test loss: 27.38819646835327 , test accuracy: 0.3229166716337204\n",
            "Test loss: 30.192317485809326 , test accuracy: 0.328125\n",
            "Test loss: 25.077520847320557 , test accuracy: 0.3541666716337204\n",
            "0.40625\n",
            "Accuracy:  0.406\n",
            "Parameters:  {'f1': 16, 'f2': 64, 'f3': 44, 'k1': 7, 'k2': 7, 'k3': 7, 'l_r': 0.01}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 64, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(64, 44, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=158400, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 240.7494659423828 , test accuracy: 0.19270833395421505\n",
            "Test loss: 215.4611053466797 , test accuracy: 0.2552083358168602\n",
            "Test loss: 206.67930793762207 , test accuracy: 0.1666666679084301\n",
            "Test loss: 245.14339447021484 , test accuracy: 0.20833333395421505\n",
            "Test loss: 222.1466064453125 , test accuracy: 0.2083333358168602\n",
            "Test loss: 129.55190563201904 , test accuracy: 0.2604166679084301\n",
            "Test loss: 162.80604553222656 , test accuracy: 0.2552083358168602\n",
            "Test loss: 130.76331329345703 , test accuracy: 0.25\n",
            "Test loss: 154.93574905395508 , test accuracy: 0.296875\n",
            "Test loss: 125.91961669921875 , test accuracy: 0.2760416679084301\n",
            "Test loss: 121.32942771911621 , test accuracy: 0.2864583358168602\n",
            "Test loss: 132.27699851989746 , test accuracy: 0.3333333358168602\n",
            "Test loss: 135.118896484375 , test accuracy: 0.328125\n",
            "Test loss: 105.07577896118164 , test accuracy: 0.22395833395421505\n",
            "Test loss: 89.21751976013184 , test accuracy: 0.3229166716337204\n",
            "Test loss: 77.61254692077637 , test accuracy: 0.3229166679084301\n",
            "Test loss: 80.2409839630127 , test accuracy: 0.3385416716337204\n",
            "Test loss: 104.7515754699707 , test accuracy: 0.28125\n",
            "Test loss: 81.26151180267334 , test accuracy: 0.28125\n",
            "Test loss: 80.39353561401367 , test accuracy: 0.359375\n",
            "Test loss: 108.84903717041016 , test accuracy: 0.265625\n",
            "Test loss: 106.13391494750977 , test accuracy: 0.2760416716337204\n",
            "Test loss: 76.84535026550293 , test accuracy: 0.2864583358168602\n",
            "Test loss: 69.23784255981445 , test accuracy: 0.2916666716337204\n",
            "Test loss: 88.17570114135742 , test accuracy: 0.3072916679084301\n",
            "Test loss: 85.8882303237915 , test accuracy: 0.265625\n",
            "Test loss: 63.571624755859375 , test accuracy: 0.3072916679084301\n",
            "Test loss: 81.6936845779419 , test accuracy: 0.2864583358168602\n",
            "Test loss: 71.61273574829102 , test accuracy: 0.3333333358168602\n",
            "Test loss: 75.89154052734375 , test accuracy: 0.2864583358168602\n",
            "Test loss: 58.07201957702637 , test accuracy: 0.359375\n",
            "Test loss: 65.67808532714844 , test accuracy: 0.28125\n",
            "Test loss: 67.58980560302734 , test accuracy: 0.3125\n",
            "Test loss: 61.291893005371094 , test accuracy: 0.3020833358168602\n",
            "Test loss: 64.80538845062256 , test accuracy: 0.2760416679084301\n",
            "Test loss: 57.08429002761841 , test accuracy: 0.3020833358168602\n",
            "Test loss: 57.715850830078125 , test accuracy: 0.265625\n",
            "Test loss: 53.7169451713562 , test accuracy: 0.234375\n",
            "Test loss: 52.67838191986084 , test accuracy: 0.2604166679084301\n",
            "Test loss: 55.86820697784424 , test accuracy: 0.3072916716337204\n",
            "Test loss: 50.66813850402832 , test accuracy: 0.3385416716337204\n",
            "Test loss: 58.660340309143066 , test accuracy: 0.359375\n",
            "Test loss: 44.20106267929077 , test accuracy: 0.2864583358168602\n",
            "Test loss: 48.69363880157471 , test accuracy: 0.2760416679084301\n",
            "Test loss: 66.56288242340088 , test accuracy: 0.2291666679084301\n",
            "Test loss: 44.976040840148926 , test accuracy: 0.22395833395421505\n",
            "Test loss: 44.73115062713623 , test accuracy: 0.265625\n",
            "Test loss: 50.13173294067383 , test accuracy: 0.3020833358168602\n",
            "Test loss: 49.67006492614746 , test accuracy: 0.2916666716337204\n",
            "Test loss: 48.06319713592529 , test accuracy: 0.3177083358168602\n",
            "0.359375\n",
            "Accuracy:  0.359\n",
            "Parameters:  {'f1': 32, 'f2': 64, 'f3': 44, 'k1': 7, 'k2': 17, 'k3': 11, 'l_r': 0.01}\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(17, 17), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(64, 44, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=93104, out_features=4, bias=True)\n",
            ")\n",
            "Test loss: 102.24657154083252 , test accuracy: 0.3177083358168602\n",
            "Test loss: 139.09377098083496 , test accuracy: 0.296875\n",
            "Test loss: 92.55548286437988 , test accuracy: 0.3072916716337204\n",
            "Test loss: 131.57550811767578 , test accuracy: 0.3229166716337204\n",
            "Test loss: 86.88310718536377 , test accuracy: 0.2291666716337204\n",
            "Test loss: 83.12772560119629 , test accuracy: 0.27083333395421505\n",
            "Test loss: 56.37747669219971 , test accuracy: 0.2395833358168602\n",
            "Test loss: 47.23744583129883 , test accuracy: 0.2916666679084301\n",
            "Test loss: 39.88813638687134 , test accuracy: 0.2604166679084301\n",
            "Test loss: 42.09418344497681 , test accuracy: 0.3177083358168602\n",
            "Test loss: 36.2780556678772 , test accuracy: 0.3020833358168602\n",
            "Test loss: 30.06140112876892 , test accuracy: 0.25520833395421505\n",
            "Test loss: 32.091562032699585 , test accuracy: 0.2291666679084301\n",
            "Test loss: 30.910547733306885 , test accuracy: 0.1979166679084301\n",
            "Test loss: 23.480843544006348 , test accuracy: 0.234375\n",
            "Test loss: 26.959177017211914 , test accuracy: 0.1979166679084301\n",
            "Test loss: 24.719467163085938 , test accuracy: 0.27083333395421505\n",
            "Test loss: 24.03926110267639 , test accuracy: 0.21875\n",
            "Test loss: 21.24930477142334 , test accuracy: 0.25\n",
            "Test loss: 20.321500301361084 , test accuracy: 0.2916666679084301\n",
            "Test loss: 17.562963247299194 , test accuracy: 0.3333333358168602\n",
            "Test loss: 19.07268738746643 , test accuracy: 0.2916666716337204\n",
            "Test loss: 19.501641035079956 , test accuracy: 0.2083333358168602\n",
            "Test loss: 20.5354106426239 , test accuracy: 0.25520833395421505\n",
            "Test loss: 20.009716987609863 , test accuracy: 0.28125\n",
            "Test loss: 18.116270065307617 , test accuracy: 0.3229166716337204\n",
            "Test loss: 16.91860818862915 , test accuracy: 0.2760416716337204\n",
            "Test loss: 15.96257996559143 , test accuracy: 0.3125\n",
            "Test loss: 16.577315092086792 , test accuracy: 0.2552083358168602\n",
            "Test loss: 14.657856702804565 , test accuracy: 0.3333333358168602\n",
            "Test loss: 15.182884693145752 , test accuracy: 0.2447916679084301\n",
            "Test loss: 14.95710802078247 , test accuracy: 0.265625\n",
            "Test loss: 19.005977272987366 , test accuracy: 0.3177083432674408\n",
            "Test loss: 14.276750683784485 , test accuracy: 0.3229166716337204\n",
            "Test loss: 16.54897630214691 , test accuracy: 0.2395833358168602\n",
            "Test loss: 15.466799318790436 , test accuracy: 0.3333333432674408\n",
            "Test loss: 17.118340253829956 , test accuracy: 0.1979166679084301\n",
            "Test loss: 13.359984397888184 , test accuracy: 0.34375\n",
            "Test loss: 17.513793110847473 , test accuracy: 0.3125\n",
            "Test loss: 15.132835626602173 , test accuracy: 0.28125\n",
            "Test loss: 20.680917263031006 , test accuracy: 0.3125\n",
            "Test loss: 18.010915994644165 , test accuracy: 0.3020833358168602\n",
            "Test loss: 15.82627785205841 , test accuracy: 0.2135416679084301\n",
            "Test loss: 17.163975715637207 , test accuracy: 0.265625\n",
            "Test loss: 21.127644062042236 , test accuracy: 0.2604166679084301\n",
            "Test loss: 15.965110898017883 , test accuracy: 0.2760416679084301\n",
            "Test loss: 24.7630672454834 , test accuracy: 0.25\n",
            "Test loss: 16.395355463027954 , test accuracy: 0.2447916679084301\n",
            "Test loss: 18.617244482040405 , test accuracy: 0.296875\n",
            "Test loss: 15.802784442901611 , test accuracy: 0.3177083358168602\n",
            "0.34375\n",
            "Accuracy:  0.344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d4b924bdac4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mchild1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mchild2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-b976c39c1c0d>\u001b[0m in \u001b[0;36mmutation\u001b[0;34m(chromosome)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"f2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mchromosome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8325mvkcRBOP"
      },
      "source": [
        " \n",
        "plt.plot(trainloss_values, 'g', label='Training loss')\n",
        "plt.plot(testloss_values, 'b', label='Test loss')\n",
        "plt.title('Training and Test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC51xfOJSkJE"
      },
      "source": [
        " \n",
        "plt.plot(trainacc_values, 'g', label='Training accuracy')\n",
        "plt.plot(testacc_values, 'b', label='Test accuracy')\n",
        "plt.title('Training and Test accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4srjUn47Pin"
      },
      "source": [
        "0.00075 --- 10) 84, 74 . 20) 90 ,93\n",
        "0.001  --- 10) 69, 75. 20) 92 93\n",
        "0.0005 --- 10) 85, 80 . 20) 88, 89\n",
        "0.0001 -- 10) 82, 76 . 20) 94, 89"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHklMHJDqgZu"
      },
      "source": [
        "def initialization():  \n",
        "  parameters = {}\n",
        "  f1 = choice([16, 24, 32])\n",
        "  parameters[\"f1\"] = f1\n",
        "  f2 = choice([ 32,40, 64, 80])\n",
        "  parameters[\"f2\"] = f2\n",
        "  f3 = choice([40, 64, 128])\n",
        "  parameters[\"f3\"] = f3\n",
        "  k = choice([3,7, 13])\n",
        "  parameters[\"k\"] = k\n",
        "  l_r= choice([0.001, 0.00025, 0.0005, 0.00075])\n",
        "\n",
        "  \n",
        "  return parameters\n",
        "\n",
        "def generate_population(n):\n",
        "  population = []\n",
        "  for i in range(n):\n",
        "    chromosome = initialization()\n",
        "    population.append(chromosome)\n",
        "  return population\n",
        "\n",
        "\n",
        "return max(testacc_values)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOiqMKyQk8Vz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}